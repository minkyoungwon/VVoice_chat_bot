import { useRef, useCallback, useEffect } from 'react';
import { v4 as uuidv4 } from 'uuid';

// í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
const WS_BASE_URL = import.meta.env.VITE_WS_BASE_URL || 'ws://localhost:8000';

export const useConversationWebSocket = () => {
  const wsRef = useRef(null);
  const clientIdRef = useRef(uuidv4());
  const currentStreamIdRef = useRef(null); // ğŸ”¥ í˜„ì¬ ìŠ¤íŠ¸ë¦¼ ID ì¶”ì 
  const pendingAudioChunkRef = useRef(null); // ğŸ”¥ ëŒ€ê¸° ì¤‘ì¸ ì˜¤ë””ì˜¤ ì²­í¬ ë©”íƒ€ë°ì´í„°
  
  const connect = useCallback((onMessage, onOpen, onClose, onError) => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.close();
    }
    
    const url = `${WS_BASE_URL}/ws/conversation/${clientIdRef.current}`;
    wsRef.current = new WebSocket(url);
    
    wsRef.current.onopen = onOpen || (() => {});
    wsRef.current.onclose = onClose || (() => {});
    wsRef.current.onerror = onError || (() => {});
    
    wsRef.current.onmessage = (event) => {
      try {
        // ğŸ”¥ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì²˜ë¦¬ ê°œì„  - Blobê³¼ ArrayBuffer ëª¨ë‘ ì²˜ë¦¬
        if (event.data instanceof ArrayBuffer) {
          console.log('ğŸ“Š ArrayBuffer ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ :', event.data.byteLength, 'bytes');
          // ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
          const pendingMeta = pendingAudioChunkRef.current;
          if (pendingMeta && pendingMeta.stream_id === currentStreamIdRef.current) {
            // ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ë‹¬
            onMessage?.({
              event: 'audio_chunk_binary',
              ...pendingMeta,
              audioData: event.data
            });
            pendingAudioChunkRef.current = null;
          } else {
            console.warn('âš ï¸ ë©”íƒ€ë°ì´í„° ì—†ëŠ” ArrayBuffer ë°ì´í„° ë¬´ì‹œ');
          }
        } else if (event.data instanceof Blob) {
          console.log('ğŸ“Š Blob ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ :', event.data.size, 'bytes');
          // Blobì„ ArrayBufferë¡œ ë³€í™˜
          event.data.arrayBuffer().then(arrayBuffer => {
            const pendingMeta = pendingAudioChunkRef.current;
            if (pendingMeta && pendingMeta.stream_id === currentStreamIdRef.current) {
              console.log('âœ… Blob -> ArrayBuffer ë³€í™˜ ì™„ë£Œ:', arrayBuffer.byteLength, 'bytes');
              onMessage?.({
                event: 'audio_chunk_binary',
                ...pendingMeta,
                audioData: arrayBuffer
              });
              pendingAudioChunkRef.current = null;
            } else {
              console.warn('âš ï¸ ë©”íƒ€ë°ì´í„° ì—†ëŠ” Blob ë°ì´í„° ë¬´ì‹œ');
            }
          }).catch(error => {
            console.error('âŒ Blob -> ArrayBuffer ë³€í™˜ ì‹¤íŒ¨:', error);
          });
        } else if (typeof event.data === 'string') {
          // JSON ë©”ì‹œì§€ ì²˜ë¦¬
          try {
            const data = JSON.parse(event.data);
            console.log('ğŸ“¨ JSON ë©”ì‹œì§€ ìˆ˜ì‹ :', data.event || data.type || 'unknown');
            
            // ğŸ”¥ ì˜¤ë””ì˜¤ ì²­í¬ ë©”íƒ€ë°ì´í„° ì €ì¥
            if (data.event === 'audio_chunk_meta') {
              console.log('ğŸ“ ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì €ì¥:', data.stream_id, data.chunk_index);
              pendingAudioChunkRef.current = data;
              
              // ë©”íƒ€ë°ì´í„°ë§Œ ì „ë‹¬í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„í•  ìˆ˜ ìˆë„ë¡ í•¨
              onMessage?.(data);
            } else {
              onMessage?.(data);
            }
          } catch (parseError) {
            console.error('âŒ JSON íŒŒì‹± ì˜¤ë¥˜:', parseError);
            console.error('ì›ë³¸ ë°ì´í„°:', event.data);
          }
        } else {
          console.warn('âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„° íƒ€ì…:', typeof event.data, event.data);
        }
      } catch (e) {
        console.error('âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜:', e);
      }
    };
    
    return wsRef.current;
  }, []);
  
  const sendConfiguration = useCallback((config) => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify(config));
    }
  }, []);
  
  const sendAudioChunk = useCallback((audioData) => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(audioData);
    }
  }, []);
  
  const sendCommand = useCallback((command) => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(command);
    }
  }, []);
  
  const close = useCallback(() => {
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
    currentStreamIdRef.current = null; // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ID ì´ˆê¸°í™”
    pendingAudioChunkRef.current = null; // ğŸ”¥ ëŒ€ê¸° ì¤‘ì¸ ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
  }, []);
  
  const isConnected = useCallback(() => {
    return wsRef.current?.readyState === WebSocket.OPEN;
  }, []);
  
  useEffect(() => {
    return () => {
      if (wsRef.current) {
        wsRef.current.close();
      }
    };
  }, []);
  
  return { 
    connect, 
    sendConfiguration, 
    sendAudioChunk, 
    sendCommand, 
    close, 
    isConnected,
    clientId: clientIdRef.current,
    currentStreamIdRef, // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ID ì°¸ì¡° ë…¸ì¶œ
    pendingAudioChunkRef // ğŸ”¥ ë©”íƒ€ë°ì´í„° ì°¸ì¡° ë…¸ì¶œ
  };
};

export const useConversationFlow = () => {
  const { 
    connect, 
    sendConfiguration, 
    sendAudioChunk, 
    sendCommand, 
    close, 
    isConnected,
    clientId,
    currentStreamIdRef,
    pendingAudioChunkRef
  } = useConversationWebSocket();
  
  const connectConversation = useCallback((
    onSTTResult,
    onGPTResponse, 
    onTTSStart,
    onTTSAudio,
    onTTSComplete,
    onError,
    onStateChange
  ) => {
    const handleMessage = (data) => {
      switch (data.event) {
        case 'stt_completed':
          onSTTResult?.(data.transcript);
          break;
          
        case 'stt_empty':
          onSTTResult?.('');
          break;
          
        case 'gpt_response':
          onGPTResponse?.(data.response);
          break;
          
        case 'tts_started':
          onTTSStart?.(data.sr, data.dtype);
          break;
          
        // ğŸ”¥ ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì²˜ë¦¬
        case 'audio_stream_start':
          console.log('ğŸµ ìƒˆ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘:', data.stream_id);
          currentStreamIdRef.current = data.stream_id;
          onTTSStart?.(data.sample_rate, 'int16');
          break;
          
        // ğŸ”¥ ì´ì „ ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨ ì²˜ë¦¬
        case 'audio_stop_previous':
          console.log('ğŸ”‡ ì´ì „ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨');
          onStateChange?.('audio_stop_previous');
          break;
          
        // ğŸ”¥ ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ - ë””ë²„ê¹… ê°•í™”
        case 'audio_chunk_binary':
          console.log('ğŸµ ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ :', {
            streamId: data.stream_id,
            currentStreamId: currentStreamIdRef.current,
            chunkIndex: data.chunk_index,
            totalChunks: data.total_chunks,
            audioDataSize: data.audioData?.byteLength,
            isFinalChunk: data.is_final_chunk
          });
          
          // ìŠ¤íŠ¸ë¦¼ ID ê²€ì¦ - í˜„ì¬ ìŠ¤íŠ¸ë¦¼ë§Œ ì²˜ë¦¬
          if (data.stream_id && data.stream_id === currentStreamIdRef.current) {
            if (data.audioData && data.audioData.byteLength > 0) {
              console.log(`âœ… ì˜¤ë””ì˜¤ ì²­í¬ ì „ë‹¬: ${data.chunk_index + 1}/${data.total_chunks}`);
              onTTSAudio?.(data.audioData);
            } else {
              console.warn('âš ï¸ ë¹ˆ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ ');
            }
            
            // ğŸ”¥ ìµœì¢… ì²­í¬ì¸ ê²½ìš° ì™„ë£Œ ì²˜ë¦¬ ì¤€ë¹„
            if (data.is_final_chunk) {
              console.log('ğŸ“¤ ìµœì¢… ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ ë¨');
            }
          } else {
            console.log('âš ï¸ ì˜ëª»ëœ ìŠ¤íŠ¸ë¦¼ IDì˜ ì˜¤ë””ì˜¤ ì²­í¬ ë¬´ì‹œ:', {
              receivedStreamId: data.stream_id,
              expectedStreamId: currentStreamIdRef.current
            });
          }
          break;
          
        // ğŸ”¥ ë ˆê±°ì‹œ JSON ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ (í˜¸í™˜ì„±)
        case 'audio_chunk':
          console.warn('âš ï¸ ë ˆê±°ì‹œ JSON ì˜¤ë””ì˜¤ ì²­í¬ ë°œê²¬ - ë°”ì´ë„ˆë¦¬ë¡œ ì—…ë°ì´íŠ¸ ê¶Œì¥');
          const audioArray = new Int16Array(data.data);
          onTTSAudio?.(audioArray.buffer);
          break;
          
        // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ ì²˜ë¦¬
        case 'audio_stream_complete':
          if (data.stream_id === currentStreamIdRef.current) {
            console.log('âœ… ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ:', data.stream_id);
            onTTSComplete?.();
            currentStreamIdRef.current = null;
          }
          break;
          
        // ğŸ”¥ ìƒˆë¡œìš´ ê°„ë‹¨í•œ JSON ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ - ê°•í™”
        case 'audio_data_complete':
          console.log('ğŸµ ì „ì²´ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ :', {
            format: data.format,
            sampleRate: data.sample_rate,
            duration: data.duration,
            rtf: data.rtf,
            dataSize: data.audio_data?.length,
            dataPreview: data.audio_data?.substring(0, 50) + '...' // Base64 ë¬¸ìì—´ ë¯¸ë¦¬ë³´ê¸°
          });
          
          if (data.audio_data && data.format === 'pcm_int16_base64') {
            try {
              // Base64 ë””ì½”ë”©
              console.log('ğŸ” Base64 ë””ì½”ë”© ì‹œì‘:', {
                base64Length: data.audio_data.length,
                base64Preview: data.audio_data.substring(0, 100)
              });
              
              const binaryString = atob(data.audio_data);
              console.log('ğŸ” atob ê²°ê³¼:', {
                binaryStringLength: binaryString.length,
                firstCharCodes: Array.from(binaryString.substring(0, 20)).map(c => c.charCodeAt(0))
              });
              
              const bytes = new Uint8Array(binaryString.length);
              for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
              }
              
              console.log('ğŸ” Uint8Array ë³€í™˜:', {
                bytesLength: bytes.length,
                first20Bytes: Array.from(bytes.slice(0, 20)),
                first20Hex: Array.from(bytes.slice(0, 20)).map(b => b.toString(16).padStart(2, '0')).join(' ')
              });
              
              // ArrayBufferë¡œ ë³€í™˜
              const audioBuffer = bytes.buffer;
              
              console.log('âœ… Base64 -> ArrayBuffer ë³€í™˜ ì™„ë£Œ:', {
                arrayBufferSize: audioBuffer.byteLength,
                expectedSamples: audioBuffer.byteLength / 2, // 16-bit = 2 bytes per sample
                serverSampleRate: data.sample_rate,
                estimatedDuration: (audioBuffer.byteLength / 2) / data.sample_rate
              });
              
              // ğŸ”¥ ë” ìì„¸í•œ ë””ë²„ê¹…: Int16Arrayë¡œ ë³€í™˜í•´ì„œ ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„° í™•ì¸
              const int16View = new Int16Array(audioBuffer);
              const maxSample = Math.max(...int16View.slice(0, Math.min(1000, int16View.length)));
              const minSample = Math.min(...int16View.slice(0, Math.min(1000, int16View.length)));
              
              console.log('ğŸ“Š ë””ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° ë¶„ì„:', {
                samples: int16View.length,
                maxSample: maxSample,
                minSample: minSample,
                firstFewSamples: Array.from(int16View.slice(0, 10)),
                isQuiet: Math.abs(maxSample) < 100 && Math.abs(minSample) < 100
              });
              
              if (Math.abs(maxSample) < 10 && Math.abs(minSample) < 10) {
                console.warn('âš ï¸ ë””ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë§¤ìš° ì¡°ìš©í•˜ê±°ë‚˜ ë¬´ìŒì…ë‹ˆë‹¤!');
              }
              
              // ğŸ”¥ ì„œë²„ì˜ ìƒ˜í”Œë ˆì´íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ TTS ì˜¤ë””ì˜¤ í•¸ë“¤ëŸ¬ë¡œ ì „ë‹¬
              onTTSAudio?.(audioBuffer, data.sample_rate || 24000);
              
            } catch (error) {
              console.error('âŒ Base64 ë””ì½”ë”© ì˜¤ë¥˜:', error);
              console.error('ì˜¤ë¥˜ ìŠ¤íƒ:', error.stack);
              onError?.('Base64 ì˜¤ë””ì˜¤ ë””ì½”ë”© ì‹¤íŒ¨');
            }
          } else {
            console.warn('âš ï¸ ì˜ëª»ëœ ì˜¤ë””ì˜¤ ë°ì´í„° í˜•ì‹:', data.format);
          }
          break;
          
        case 'tts_completed':
          onTTSComplete?.();
          currentStreamIdRef.current = null; // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ ì‹œ ID ì´ˆê¸°í™”
          break;
          
        case 'tts_stopped':
          onStateChange?.('tts_stopped');
          currentStreamIdRef.current = null; // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨ ì‹œ ID ì´ˆê¸°í™”
          break;
          
        case 'config_updated':
          onStateChange?.('config_updated', data.settings);
          break;
          
        // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜ ì²˜ë¦¬
        case 'audio_stream_error':
          console.error('âŒ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜:', data.error);
          onError?.(data.error || 'Audio stream error');
          currentStreamIdRef.current = null;
          break;
          
        default:
          if (data.error) {
            onError?.(data.error);
          }
          break;
      }
    };
    
    return connect(
      handleMessage,
      () => {
        console.log('ğŸ”— ëŒ€í™”í˜• WebSocket ì—°ê²°ë¨ - URL:', `${WS_BASE_URL}/ws/conversation/${clientId}`);
        onStateChange?.('connected');
      },
      (event) => {
        console.log('ğŸ”Œ ëŒ€í™”í˜• WebSocket ì—°ê²° í•´ì œë¨ - Code:', event.code, 'Reason:', event.reason);
        currentStreamIdRef.current = null; // ğŸ”¥ ì—°ê²° í•´ì œ ì‹œ ìŠ¤íŠ¸ë¦¼ ID ì´ˆê¸°í™”
        onStateChange?.('disconnected');
      },
      (error) => {
        console.error('âŒ ëŒ€í™”í˜• WebSocket ì˜¤ë¥˜:', error);
        console.error('ì—°ê²° URL:', `${WS_BASE_URL}/ws/conversation/${clientId}`);
        currentStreamIdRef.current = null; // ğŸ”¥ ì˜¤ë¥˜ ì‹œ ìŠ¤íŠ¸ë¦¼ ID ì´ˆê¸°í™”
        onError?.(error);
      }
    );
  }, [connect]);
  
  const updateSettings = useCallback((settings) => {
    sendConfiguration(settings);
  }, [sendConfiguration]);
  
  const startRecording = useCallback(() => {
    // ë…¹ìŒ ì‹œì‘ì€ ë³„ë„ì˜ Web Audio APIë¡œ ì²˜ë¦¬
    // ì—¬ê¸°ì„œëŠ” ì„œë²„ì— ë…¹ìŒ ì‹œì‘ì„ ì•Œë¦¼
    sendCommand('start_recording');
  }, [sendCommand]);
  
  const stopRecording = useCallback(() => {
    sendCommand('stop_recording');
  }, [sendCommand]);
  
  const stopSpeaking = useCallback(() => {
    // ğŸ”¥ í˜„ì¬ ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨
    console.log('ğŸ”‡ ìŒì„± ì¬ìƒ ì¤‘ë‹¨ ìš”ì²­');
    sendCommand('stop_speaking');
    currentStreamIdRef.current = null; // ìŠ¤íŠ¸ë¦¼ ID ì´ˆê¸°í™”
  }, [sendCommand, currentStreamIdRef]);
  
  const sendVoiceData = useCallback((audioData) => {
    sendAudioChunk(audioData);
  }, [sendAudioChunk]);
  
  return {
    connectConversation,
    updateSettings,
    startRecording,
    stopRecording,
    stopSpeaking,
    sendVoiceData,
    close,
    isConnected,
    clientId
  };
};
