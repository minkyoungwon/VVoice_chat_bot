import React, { useState, useCallback, useEffect, useRef } from 'react';
import { useConversationFlow } from '../hooks/useConversation';
import { useAudioPlayer } from '../hooks/useAudio';
import { useVADRecorder } from '../hooks/useVAD';
import useChatStore from '../store/chatStore';
import FullScreenAvatar from './FullScreenAvatar';
import TTSEmotionControl from './TTSEmotionControl';
import VADControl from './VADControl';
import '../styles/SimpleVoiceChat.css';

const SimpleVoiceChat = () => {
  const {
    isConnected,
    isRecording,
    isSpeaking,
    currentTranscript,
    error,
    setConnected,
    setRecording,
    setSpeaking,
    setCurrentTranscript,
    addUserMessage,
    addAssistantMessage,
    addSystemMessage,
    setError,
    clearError
  } = useChatStore();
  
  // ğŸ”¥ ê°„ë‹¨í•œ ìƒíƒœ ê´€ë¦¬
  const [conversationActive, setConversationActive] = useState(false); // ì—°ì† ëŒ€í™” ëª¨ë“œ
  const [currentStatus, setCurrentStatus] = useState('disconnected'); // disconnected, ready, talking, listening, thinking
  const [processingStep, setProcessingStep] = useState(''); // STT, GPT, TTS
  const [showFullScreen, setShowFullScreen] = useState(false); // ì „ì²´ í™”ë©´ ëª¨ë“œ
  const [isVADEnabled, setIsVADEnabled] = useState(true); // VAD ê¸°ë³¸ í™œì„±í™”
  const [showTTSControls, setShowTTSControls] = useState(false); // TTS ê°ì • ì¡°ì ˆ UI í‘œì‹œ
  const [showVADControls, setShowVADControls] = useState(false); // VAD ì„¤ì • UI í‘œì‹œ
  const [currentSettings, setCurrentSettings] = useState({ // í˜„ì¬ ì„¤ì • ìƒíƒœ
    tts_settings: {
      model: "Zyphra/Zonos-v0.1-tiny",
      emotion: "neutral",
      intensity: 0.7,
      speed: 1.0,
      cfg_scale: 1.5
    },
    vadConfig: {
      voiceThreshold: 0.08,
      silenceThreshold: 0.03,
      minVoiceDuration: 300,
      maxSilenceDuration: 1200,
      bufferDuration: 300,
      sensitivity: 'medium'
    }
  });
  
  // ğŸ“ refë¥¼ í†µí•œ ìƒíƒœ ì°¸ì¡° (ì˜ì¡´ì„± ìˆœí™˜ ë°©ì§€)
  const conversationActiveRef = useRef(false);
  const isVADEnabledRef = useRef(true);
  
  // ref ë™ê¸°í™”
  useEffect(() => {
    conversationActiveRef.current = conversationActive;
  }, [conversationActive]);
  
  useEffect(() => {
    isVADEnabledRef.current = isVADEnabled;
  }, [isVADEnabled]);
  
  // í›…ë“¤
  const conversationFlow = useConversationFlow();
  const audioPlayer = useAudioPlayer();
  const vadRecorder = useVADRecorder();
  
  // ğŸ”¥ startListeningì„ refë¡œ ì €ì¥ (ì˜ì¡´ì„± ìˆœí™˜ ë°©ì§€)
  const startListeningRef = useRef();
  
  // ğŸ”¥ ì„¤ì • ë³€ê²½ í•¸ë“¤ëŸ¬
  const handleTTSSettingsChange = useCallback((newSettings) => {
    console.log('ğŸ­ TTS ì„¤ì • ë³€ê²½:', newSettings);
    
    const updatedSettings = {
      ...currentSettings,
      ...newSettings
    };
    
    setCurrentSettings(updatedSettings);
    
    // ì—°ê²°ëœ ìƒíƒœì—ì„œë§Œ ì„œë²„ì— ì„¤ì • ì „ì†¡
    if (isConnected) {
      conversationFlow.updateSettings({
        language: "ko",
        ...newSettings,
        performance_mode: "fast",
        system_prompt: "ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”. í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
      });
    }
  }, [currentSettings, isConnected, conversationFlow]);
  
  const handleVADSettingsChange = useCallback((newSettings) => {
    console.log('ğŸ¤ VAD ì„¤ì • ë³€ê²½:', newSettings);
    
    const updatedSettings = {
      ...currentSettings,
      ...newSettings
    };
    
    setCurrentSettings(updatedSettings);
    
    // VAD ë…¹ìŒ ì¤‘ì´ë©´ ìƒˆ ì„¤ì • ì ìš©
    if (vadRecorder.isRecording && newSettings.vadConfig) {
      vadRecorder.updateVADConfig(newSettings.vadConfig);
    }
  }, [currentSettings, vadRecorder]);
  
  // ğŸ”¥ STT ê²°ê³¼ ì²˜ë¦¬
  const handleSTTResult = useCallback((transcript) => {
    console.log('ğŸ¤ STT ê²°ê³¼:', transcript);
    setCurrentTranscript(transcript);
    
    if (transcript.trim()) {
      addUserMessage(transcript);
      setCurrentStatus('thinking');
      setProcessingStep('GPT ì‘ë‹µ ìƒì„± ì¤‘...');
    } else {
      if (conversationActiveRef.current) {
        // ë¹ˆ ìŒì„±ì´ë©´ ë‹¤ì‹œ ë“£ê¸° ì‹œì‘
        setTimeout(() => {
          setCurrentStatus('listening');
          setProcessingStep('');
          if (startListeningRef.current) {
            startListeningRef.current();
          }
        }, 1000);
      } else {
        setCurrentStatus('ready');
        setProcessingStep('');
      }
    }
  }, [addUserMessage, setCurrentTranscript]);
  
  // ğŸ”¥ GPT ì‘ë‹µ ì²˜ë¦¬
  const handleGPTResponse = useCallback((response) => {
    console.log('ğŸ¤– GPT ì‘ë‹µ:', response);
    addAssistantMessage(response);
    setCurrentStatus('talking');
    setProcessingStep('ìŒì„± ìƒì„± ì¤‘...');
  }, [addAssistantMessage]);
  
  // ğŸ”¥ TTS ì‹œì‘ ì²˜ë¦¬
  const handleTTSStart = useCallback((sampleRate, dtype) => {
    console.log('ğŸ—£ï¸ TTS ì‹œì‘');
    setSpeaking(true);
    audioPlayer.startNewAudio();
    setCurrentStatus('talking');
    setProcessingStep('ìŒì„± ì¬ìƒ ì¤‘...');
  }, [audioPlayer, setSpeaking]);
  
  // ğŸ”¥ TTS ì˜¤ë””ì˜¤ ì²˜ë¦¬
  const handleTTSAudio = useCallback(async (audioBuffer, sampleRate = 24000) => {
    try {
      await audioPlayer.playPCMChunk(audioBuffer, sampleRate);
    } catch (error) {
      console.error('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error);
      setError('ìŒì„± ì¬ìƒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  }, [audioPlayer, setError]);
  
  // ğŸ”¥ TTS ì™„ë£Œ ì²˜ë¦¬
  const handleTTSComplete = useCallback(() => {
    console.log('âœ… TTS ì™„ë£Œ');
    setSpeaking(false);
    setProcessingStep('');
    
    if (conversationActiveRef.current) {
      // ğŸ”¥ ì—°ì† ëª¨ë“œ: ìë™ìœ¼ë¡œ ë‹¤ìŒ ë“£ê¸° ì‹œì‘
      setTimeout(() => {
        setCurrentStatus('listening');
        if (startListeningRef.current) {
          startListeningRef.current();
        }
      }, 1500); // 1.5ì´ˆ í›„ ìë™ ì‹œì‘
    } else {
      setCurrentStatus('ready');
    }
  }, [setSpeaking]);
  
  // ğŸ”¥ ì—ëŸ¬ ì²˜ë¦¬
  const handleError = useCallback((error) => {
    console.error('âŒ ëŒ€í™” ì˜¤ë¥˜:', error);
    setError(typeof error === 'string' ? error : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    setCurrentStatus('ready');
    setProcessingStep('');
    setSpeaking(false);
    setRecording(false);
  }, [setError, setSpeaking, setRecording]);
  
  // ğŸ”¥ ìƒíƒœ ë³€ê²½ ì²˜ë¦¬
  const handleStateChange = useCallback((state, data) => {
    console.log('ğŸ“Š ìƒíƒœ ë³€ê²½:', state, data);
    
    switch (state) {
      case 'connected':
        setConnected(true);
        setCurrentStatus('ready');
        break;
      case 'disconnected':
        setConnected(false);
        setCurrentStatus('disconnected');
        setConversationActive(false);
        break;
      case 'audio_stop_previous':
        audioPlayer.startNewAudio();
        break;
    }
  }, [setConnected, audioPlayer]);
  
  // ğŸ”¥ VAD ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤
  const handleVoiceStart = useCallback(() => {
    console.log('ğŸ¤ VAD: ìŒì„± ì‹œì‘ ê°ì§€');
    
    // ğŸ”¥ TTS ì¤‘ì— ìŒì„±ì´ ê°ì§€ë˜ë©´ TTS ì¤‘ë‹¨
    if (isSpeaking) {
      console.log('ğŸ”‡ TTS ì¤‘ì— ìŒì„± ê°ì§€ - TTS ì¤‘ë‹¨');
      audioPlayer.stop(); // ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ë‹¨
      conversationFlow.stopSpeaking(); // ì„œë²„ì— TTS ì¤‘ë‹¨ ìš”ì²­
      setSpeaking(false);
      setCurrentStatus('listening');
      setProcessingStep('ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
    } else {
      setProcessingStep('ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
    }
  }, [isSpeaking, audioPlayer, conversationFlow, setSpeaking]);

  const handleVoiceEnd = useCallback(() => {
    console.log('ğŸ”‡ VAD: ìŒì„± ì¢…ë£Œ ê°ì§€');
    vadRecorder.stopRecording();
    conversationFlow.stopRecording();
    
    setRecording(false);
    setCurrentStatus('thinking');
    setProcessingStep('ìŒì„± ë¶„ì„ ì¤‘...');
  }, [vadRecorder, conversationFlow, setRecording]);

  const handleSilenceDetected = useCallback(() => {
    console.log('ğŸ¤« VAD: ê¸´ ì •ì  ê°ì§€ - ìë™ ë…¹ìŒ ì¤‘ì§€');
    if (conversationActiveRef.current && isVADEnabledRef.current) {
      // VADê°€ í™œì„±í™”ëœ ì—°ì† ëª¨ë“œì—ì„œëŠ” ìë™ìœ¼ë¡œ ë‹¤ìŒ ìŒì„± ëŒ€ê¸°
      setTimeout(() => {
        setCurrentStatus('listening');
        if (startListeningRef.current) {
          startListeningRef.current();
        }
      }, 1500);
    } else {
      setCurrentStatus('ready');
      setProcessingStep('');
    }
  }, []);

  // ğŸ”¥ PCM ë°ì´í„° í•¸ë“¤ëŸ¬
  const handlePCMData = useCallback((arrayBuffer) => {
    if (conversationFlow.isConnected()) {
      conversationFlow.sendVoiceData(arrayBuffer);
    }
  }, [conversationFlow]);
  
  // ğŸ”¥ ì—°ê²° ì‹œì‘
  const startConnection = useCallback(async () => {
    try {
      clearError();
      
      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ í™œì„±í™”
      await audioPlayer.resumeContext();
      
      // WebSocket ì—°ê²°
      await conversationFlow.connectConversation(
        handleSTTResult,
        handleGPTResponse,
        handleTTSStart,
        handleTTSAudio,
        handleTTSComplete,
        handleError,
        handleStateChange
      );
      
      // ğŸ”¥ í˜„ì¬ ì„¤ì •ìœ¼ë¡œ ì„œë²„ ì„¤ì •
      conversationFlow.updateSettings({
        language: "ko",
        ...currentSettings,
        performance_mode: "fast",
        system_prompt: "ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”. í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
      });
      
      addSystemMessage('ğŸ’¬ ëŒ€í™” ì¤€ë¹„ ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.');
      
    } catch (error) {
      console.error('âŒ ì—°ê²° ì‹¤íŒ¨:', error);
      setError('ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    }
  }, [audioPlayer, conversationFlow, handleSTTResult, handleGPTResponse, handleTTSStart, handleTTSAudio, handleTTSComplete, handleError, handleStateChange, clearError, addSystemMessage, currentSettings]);
  
  // ğŸ”¥ ë“£ê¸° ì‹œì‘ (VAD ì§€ì›) - refë¡œ ì €ì¥
  const startListening = useCallback(async () => {
    if (!isConnected) {
      setError('ë¨¼ì € ì—°ê²°ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.');
      return;
    }
    
    try {
      setCurrentTranscript('');
      clearError();
      setProcessingStep(isVADEnabledRef.current ? 'ìŒì„±ì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤... (ìë™ ê°ì§€)' : 'ìŒì„± ì¸ì‹ ì¤‘...');
      
      if (isVADEnabledRef.current) {
        // VAD ëª¨ë“œë¡œ ë…¹ìŒ ì‹œì‘ - í˜„ì¬ ì„¤ì • ì‚¬ìš©
        await vadRecorder.startRecording(handlePCMData, {
          onVoiceStart: handleVoiceStart,
          onVoiceEnd: handleVoiceEnd,
          onSilenceDetected: handleSilenceDetected,
          vadConfig: currentSettings.vadConfig
        });
      } else {
        // ì¼ë°˜ ëª¨ë“œë¡œ ë…¹ìŒ ì‹œì‘ (ê¸°ì¡´ ë°©ì‹)
        await vadRecorder.startRecording(handlePCMData);
      }
      
      setRecording(true);
      setCurrentStatus('listening');
      
    } catch (error) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', error);
      setError('ë§ˆì´í¬ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.');
      setProcessingStep('');
    }
  }, [isConnected, vadRecorder, handlePCMData, handleVoiceStart, handleVoiceEnd, handleSilenceDetected, setCurrentTranscript, clearError, setRecording, setError, currentSettings.vadConfig]);
  
  // startListeningì„ refì— ì €ì¥
  useEffect(() => {
    startListeningRef.current = startListening;
  }, [startListening]);
  
  // ğŸ”¥ ë“£ê¸° ì¤‘ì§€
  const stopListening = useCallback(() => {
    vadRecorder.stopRecording();
    conversationFlow.stopRecording();
    
    setRecording(false);
    setCurrentStatus('thinking');
    setProcessingStep('ìŒì„± ë¶„ì„ ì¤‘...');
  }, [vadRecorder, conversationFlow, setRecording]);
  
  // ğŸ”¥ ëŒ€í™” ì‹œì‘ (í•œ ë²ˆ í´ë¦­ìœ¼ë¡œ ì—°ì† ëª¨ë“œ ì‹œì‘)
  const startConversation = useCallback(async () => {
    if (!isConnected) {
      await startConnection();
      return;
    }
    
    setConversationActive(true);
    addSystemMessage(isVADEnabled ? 'ğŸ¤– VAD ëª¨ë“œë¡œ ì—°ì† ëŒ€í™” ì‹œì‘! ìë™ìœ¼ë¡œ ìŒì„±ì„ ê°ì§€í•©ë‹ˆë‹¤.' : 'ğŸ’¬ ì—°ì† ëŒ€í™” ëª¨ë“œ ì‹œì‘! AIì™€ ììœ ë¡­ê²Œ ëŒ€í™”í•˜ì„¸ìš”.');
    
    // ì¦‰ì‹œ ì²« ë²ˆì§¸ ë“£ê¸° ì‹œì‘
    await startListening();
  }, [isConnected, startConnection, addSystemMessage, startListening, isVADEnabled]);
  
  // ğŸ”¥ ëŒ€í™” ì¤‘ì§€
  const stopConversation = useCallback(() => {
    setConversationActive(false);
    
    // í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ë“¤ ëª¨ë‘ ì¤‘ì§€
    vadRecorder.stopRecording();
    audioPlayer.stop();
    conversationFlow.stopSpeaking();
    
    setRecording(false);
    setSpeaking(false);
    setCurrentStatus('ready');
    setProcessingStep('');
    
    addSystemMessage('ğŸ›‘ ëŒ€í™”ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.');
  }, [vadRecorder, audioPlayer, conversationFlow, setRecording, setSpeaking, addSystemMessage]);
  
  // ğŸ”¥ ì—°ê²° ì¢…ë£Œ
  const disconnect = useCallback(() => {
    stopConversation();
    conversationFlow.close();
    
    setConnected(false);
    setCurrentStatus('disconnected');
    addSystemMessage('ğŸ‘‹ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
  }, [stopConversation, conversationFlow, setConnected, addSystemMessage]);
  
  // ğŸ”¥ ì „ì²´ í™”ë©´ ëª¨ë“œ ì—´ê¸°
  const openFullScreen = useCallback(async () => {
    setShowFullScreen(true);
  }, []);

  // ğŸ”¥ ì „ì²´ í™”ë©´ ëª¨ë“œ ë‹«ê¸°
  const closeFullScreen = useCallback(() => {
    setShowFullScreen(false);
  }, []);

  // ğŸ”¥ ìƒíƒœë³„ ë²„íŠ¼ ë° ë©”ì‹œì§€
  const getMainButton = () => {
    if (!isConnected) {
      return (
        <>
          <button 
            className="main-button connect-button"
            onClick={startConnection}
            disabled={false}
          >
            <span className="button-icon">ğŸ”Œ</span>
            <span className="button-text">ëŒ€í™” ì‹œì‘</span>
          </button>
          
          <button 
            className="main-button fullscreen-button"
            onClick={openFullScreen}
            disabled={false}
          >
            <span className="button-icon">ğŸ”Œ</span>
            <span className="button-text">ëŒ€í™” ì‹œì‘</span>
            <span className="button-subtitle">ì „ì²´ í™”ë©´ ëª¨ë“œë¡œ ëŒ€í™”</span>
          </button>
        </>
      );
    }
    
    if (!conversationActive) {
      return (
        <button 
          className="main-button start-conversation-button"
          onClick={startConversation}
          disabled={false}
        >
          <span className="button-icon">ğŸ’¬</span>
          <span className="button-text">{isVADEnabled ? 'VAD ëŒ€í™”í•˜ê¸°' : 'ëŒ€í™”í•˜ê¸°'}</span>
          <span className="button-subtitle">{isVADEnabled ? 'ìë™ ìŒì„± ê°ì§€ ëª¨ë“œ' : 'í•œ ë²ˆ í´ë¦­ìœ¼ë¡œ ì—°ì† ëŒ€í™”'}</span>
        </button>
      );
    }
    
    // ì—°ì† ëŒ€í™” ì¤‘ì¼ ë•ŒëŠ” ì¤‘ì§€ ë²„íŠ¼ë§Œ í‘œì‹œ
    return (
      <button 
        className="main-button stop-conversation-button"
        onClick={stopConversation}
      >
        <span className="button-icon">ğŸ›‘</span>
        <span className="button-text">ëŒ€í™” ì¤‘ì§€</span>
      </button>
    );
  };
  
  const getStatusMessage = () => {
    const messages = {
      disconnected: 'ğŸ”´ ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤',
      ready: 'ğŸŸ¢ ëŒ€í™” ì¤€ë¹„ ì™„ë£Œ',
      listening: isVADEnabled ? 'ğŸ¤ ë§ì”€í•´ ì£¼ì„¸ìš”... (ìë™ ê°ì§€)' : 'ğŸ¤ ë§ì”€í•´ ì£¼ì„¸ìš”...',
      thinking: 'ğŸ¤” AIê°€ ìƒê°í•˜ê³  ìˆì–´ìš”...',
      talking: 'ğŸ—£ï¸ AIê°€ ë‹µë³€í•˜ê³  ìˆì–´ìš”...'
    };
    
    return messages[currentStatus] || messages.ready;
  };
  
  const getStatusColor = () => {
    const colors = {
      disconnected: '#f44336',
      ready: '#4caf50',
      listening: '#2196f3',
      thinking: '#9c27b0',
      talking: '#ff9800'
    };
    
    return colors[currentStatus] || colors.ready;
  };
  
  return (
    <>
      {/* ì „ì²´ í™”ë©´ ì•„ë°”íƒ€ ëª¨ë“œ */}
      {showFullScreen && (
        <FullScreenAvatar onClose={closeFullScreen} />
      )}
      
      <div className="simple-voice-chat">
        {/* ğŸ”¥ ìƒíƒœ í‘œì‹œ */}
        <div className="status-section">
          <div 
            className="status-indicator"
            style={{ '--status-color': getStatusColor() }}
          >
            <div className="status-pulse"></div>
            <div className="status-message">{getStatusMessage()}</div>
          </div>
          
          {processingStep && (
            <div className="processing-step">
              <div className="processing-spinner"></div>
              <span>{processingStep}</span>
            </div>
          )}
          
          {/* í˜„ì¬ ì¸ì‹ëœ ìŒì„± í‘œì‹œ */}
          {currentTranscript && (
            <div className="current-transcript">
              <span className="transcript-label">ì¸ì‹ëœ ìŒì„±:</span>
              <span className="transcript-text">"{currentTranscript}"</span>
            </div>
          )}
          
          {/* VAD ìŒì„± ë ˆë²¨ í‘œì‹œ */}
          {isVADEnabled && vadRecorder.isRecording && (
            <div className="vad-level-display">
              <div className="vad-header">
                <span className="vad-label">ìŒì„± ê°•ë„:</span>
                <span className={`vad-status ${vadRecorder.isVoiceDetected ? 'active' : 'inactive'}`}>
                  {vadRecorder.isVoiceDetected ? 'ğŸ¤ ìŒì„± ê°ì§€' : 'âšª ëŒ€ê¸° ì¤‘'}
                </span>
              </div>
              <div className="vad-level-bar">
                <div 
                  className="vad-level-fill"
                  style={{ width: `${Math.min(100, vadRecorder.voiceLevel * 100)}%` }}
                ></div>
              </div>
            </div>
          )}
        </div>
        
        {/* ğŸ”¥ ë©”ì¸ ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
        <div className="control-section">
          {getMainButton()}
          
          {/* ì—°ê²°ëœ ìƒíƒœì—ì„œë§Œ ì¶”ê°€ ë²„íŠ¼ë“¤ í‘œì‹œ */}
          {isConnected && (
            <>
              {/* ì„¤ì • ë²„íŠ¼ë“¤ */}
              <div className="settings-buttons">
                <button 
                  className={`secondary-button tts-settings-button ${showTTSControls ? 'active' : ''}`}
                  onClick={() => setShowTTSControls(!showTTSControls)}
                >
                  <span className="button-icon">ğŸ­</span>
                  <span className="button-text">TTS ì„¤ì •</span>
                </button>
                
                <button 
                  className={`secondary-button vad-settings-button ${showVADControls ? 'active' : ''}`}
                  onClick={() => setShowVADControls(!showVADControls)}
                >
                  <span className="button-icon">ğŸ™ï¸</span>
                  <span className="button-text">VAD ì„¤ì •</span>
                </button>
                
                {/* VAD í† ê¸€ ë²„íŠ¼ */}
                <button 
                  className={`secondary-button vad-toggle-button ${isVADEnabled ? 'active' : ''}`}
                  onClick={() => setIsVADEnabled(!isVADEnabled)}
                >
                  <span className="button-icon">{isVADEnabled ? 'ğŸ¤–' : 'ğŸšï¸'}</span>
                  <span className="button-text">{isVADEnabled ? 'VAD í™œì„±' : 'VAD ë¹„í™œì„±'}</span>
                </button>
              </div>

              <button 
                className="secondary-button disconnect-button"
                onClick={disconnect}
              >
                <span className="button-icon">ğŸ”Œ</span>
                <span className="button-text">ì—°ê²° í•´ì œ</span>
              </button>
            </>
          )}
        </div>

        {/* ğŸ”¥ TTS ê°ì • ì¡°ì ˆ UI */}
        {showTTSControls && (
          <div className="settings-panel">
            <TTSEmotionControl 
              onSettingsChange={handleTTSSettingsChange}
              currentSettings={currentSettings}
              isVisible={showTTSControls}
            />
          </div>
        )}

        {/* ğŸ”¥ VAD ì„¤ì • UI */}
        {showVADControls && (
          <div className="settings-panel">
            <VADControl 
              onSettingsChange={handleVADSettingsChange}
              currentSettings={currentSettings}
              isVisible={showVADControls}
              isRecording={vadRecorder.isRecording}
              voiceLevel={vadRecorder.voiceLevel}
              isVoiceDetected={vadRecorder.isVoiceDetected}
            />
          </div>
        )}
        
        {/* ğŸ”¥ ëŒ€í™” ëª¨ë“œì— ë”°ë¥¸ ì•ˆë‚´ ë©”ì‹œì§€ */}
        {conversationActive && (
          <div className="conversation-mode-status">
            <div className="mode-indicator">
              <span className="mode-icon">ğŸ”„</span>
              <span className="mode-text">{isVADEnabled ? 'VAD ì—°ì† ëŒ€í™” ëª¨ë“œ í™œì„±' : 'ì—°ì† ëŒ€í™” ëª¨ë“œ í™œì„±'}</span>
            </div>
            <div className="mode-description">
              {isVADEnabled 
                ? 'AIê°€ ë§í•˜ëŠ” ì¤‘ì— ìŒì„±ì„ ê°ì§€í•˜ë©´ AI ì‘ë‹µì„ ì¤‘ë‹¨í•˜ê³  ì¦‰ì‹œ ë“£ê¸° ì‹œì‘í•©ë‹ˆë‹¤. ë§ì„ ë©ˆì¶”ë©´ ìë™ìœ¼ë¡œ ë‹¤ìŒ ëŒ€í™”ê°€ ì‹œì‘ë©ë‹ˆë‹¤.'
                : 'AI ë‹µë³€ í›„ ìë™ìœ¼ë¡œ ë‹¤ìŒ ëŒ€í™”ê°€ ì‹œì‘ë©ë‹ˆë‹¤'
              }
            </div>
          </div>
        )}
        
        {/* ğŸ”¥ ìˆ˜ë™ ì»¨íŠ¸ë¡¤ (ì—°ì† ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ) */}
        {isConnected && !conversationActive && currentStatus === 'ready' && (
          <div className="manual-controls">
            <button 
              className="manual-button"
              onClick={startListening}
            >
              ğŸ¤ í•œ ë²ˆë§Œ ë§í•˜ê¸°
            </button>
          </div>
        )}
        
        {/* ğŸ”¥ ë“£ê¸° ì¤‘ì¼ ë•Œ ì¤‘ì§€ ë²„íŠ¼ (VAD ë¹„í™œì„± ì‹œë§Œ) */}
        {isRecording && !isVADEnabled && (
          <div className="listening-controls">
            <button 
              className="stop-listening-button"
              onClick={stopListening}
            >
              â¹ï¸ ë§í•˜ê¸° ì™„ë£Œ
            </button>
          </div>
        )}
        
        {/* ğŸ”¥ ì—ëŸ¬ í‘œì‹œ */}
        {error && (
          <div className="error-section">
            <div className="error-message">
              <span className="error-icon">âš ï¸</span>
              <span className="error-text">{error}</span>
              <button 
                className="error-close"
                onClick={clearError}
              >
                âœ•
              </button>
            </div>
          </div>
        )}
      </div>
    </>
  );
};

export default SimpleVoiceChat;