import React, { useState, useCallback, useEffect, useRef } from 'react';
import { useConversationFlow } from '../hooks/useConversation';
import { useAudioPlayer } from '../hooks/useAudio';
import { useVADRecorder } from '../hooks/useVAD';
import useChatStore from '../store/chatStore';
import FullScreenAvatar from './FullScreenAvatar';
import TTSEmotionControl from './TTSEmotionControl';
import VoiceTTSControl from './VoiceTTSControl';
import VADControl from './VADControl';
import LoadingProgressBar from './LoadingProgressBar';
import '../styles/SimpleVoiceChat.css';

// React SVG ì´ë¯¸ì§€ import
import reactSvg from '../assets/react.svg';

const SimpleVoiceChat = () => {
  const {
    isConnected,
    isRecording,
    isSpeaking,
    currentTranscript,
    error,
    setConnected,
    setRecording,
    setSpeaking,
    setCurrentTranscript,
    addUserMessage,
    addAssistantMessage,
    addSystemMessage,
    setError,
    clearError
  } = useChatStore();
  
  // ğŸ”¥ ê°„ë‹¨í•œ ìƒíƒœ ê´€ë¦¬
  const [conversationActive, setConversationActive] = useState(false);
  const [currentStatus, setCurrentStatus] = useState('disconnected');
  const [processingStep, setProcessingStep] = useState('');
  const [showFullScreen, setShowFullScreen] = useState(false);
  const [isVADEnabled, setIsVADEnabled] = useState(true);
  const [showTTSControls, setShowTTSControls] = useState(false);
  const [showVADControls, setShowVADControls] = useState(false);
  const [showAvatar, setShowAvatar] = useState(false);
  
  // ğŸ”¥ LoadingProgressBar ìƒíƒœ ê°œì„  - ë” ëª…í™•í•œ ìƒíƒœ ê´€ë¦¬
  const [loadingState, setLoadingState] = useState({
    isVisible: false,
    progress: 0,
    status: '',
    title: 'ë¡œë”© ì¤‘...',
    modelName: '',
    isComplete: false, // ì™„ë£Œ ì—¬ë¶€ ì¶”ê°€
    autoHideTimer: null // íƒ€ì´ë¨¸ ì°¸ì¡° ì¶”ê°€
  });
  
  const [currentSettings, setCurrentSettings] = useState({
    tts_settings: {
      model: "Zyphra/Zonos-v0.1-tiny",
      emotion: "neutral",
      intensity: 0.7,
      speed: 1.0,
      cfg_scale: 1.5
    },
    vadConfig: {
      voiceThreshold: 0.08,
      silenceThreshold: 0.03,
      minVoiceDuration: 300,
      maxSilenceDuration: 1200,
      bufferDuration: 300,
      sensitivity: 'medium'
    }
  });
  
  // ğŸ“ refë¥¼ í†µí•œ ìƒíƒœ ì°¸ì¡° (ì˜ì¡´ì„± ìˆœí™˜ ë°©ì§€)
  const conversationActiveRef = useRef(false);
  const isVADEnabledRef = useRef(true);
  
  // ref ë™ê¸°í™”
  useEffect(() => {
    conversationActiveRef.current = conversationActive;
  }, [conversationActive]);
  
  useEffect(() => {
    isVADEnabledRef.current = isVADEnabled;
  }, [isVADEnabled]);
  
  // í›…ë“¤
  const conversationFlow = useConversationFlow();
  const audioPlayer = useAudioPlayer();
  const vadRecorder = useVADRecorder();
  
  // ğŸ”¥ startListeningì„ refë¡œ ì €ì¥ (ì˜ì¡´ì„± ìˆœí™˜ ë°©ì§€)
  const startListeningRef = useRef();
  
  // ğŸ”¥ íƒ€ì´ë¨¸ ì •ë¦¬ í•¨ìˆ˜
  const clearAutoHideTimer = useCallback(() => {
    if (loadingState.autoHideTimer) {
      clearTimeout(loadingState.autoHideTimer);
      setLoadingState(prev => ({ ...prev, autoHideTimer: null }));
    }
  }, [loadingState.autoHideTimer]);
  
  // ğŸ”¥ ë¡œë”© ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜
  const resetLoadingState = useCallback(() => {
    clearAutoHideTimer();
    setLoadingState({
      isVisible: false,
      progress: 0,
      status: '',
      title: 'ë¡œë”© ì¤‘...',
      modelName: '',
      isComplete: false,
      autoHideTimer: null
    });
  }, [clearAutoHideTimer]);
  
  // ğŸ”¥ ë¡œë”© ì™„ë£Œ ì²˜ë¦¬ í•¨ìˆ˜
  const completeLoading = useCallback((delay = 2000) => {
    setLoadingState(prev => ({
      ...prev,
      isComplete: true,
      progress: 100
    }));
    
    const timer = setTimeout(() => {
      resetLoadingState();
    }, delay);
    
    setLoadingState(prev => ({ ...prev, autoHideTimer: timer }));
  }, [resetLoadingState]);
  
  // ğŸ”¥ ë°±ì—”ë“œ ë¡œë”© ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜ ê°œì„ 
  const handleBackendLoadingMessage = useCallback((data) => {
    console.log('ğŸ”„ ë°±ì—”ë“œ ë¡œë”© ë©”ì‹œì§€:', data);
    
    // ì´ë¯¸ ì™„ë£Œëœ ìƒíƒœë©´ ìƒˆë¡œìš´ ë¡œë”© ë©”ì‹œì§€ ë¬´ì‹œ (ë‹¨, ìƒˆë¡œìš´ ì‘ì—… ì‹œì‘ì€ ì œì™¸)
    if (loadingState.isComplete && !['model_loading_progress', 'generation_started'].includes(data.type)) {
      return;
    }
    
    switch (data.type) {
      case 'model_loading_progress':
        clearAutoHideTimer(); // ê¸°ì¡´ íƒ€ì´ë¨¸ ì œê±°
        setLoadingState(prev => ({
          ...prev,
          isVisible: true,
          progress: data.progress || 0,
          status: data.status || 'ë¡œë”© ì¤‘...',
          title: 'ëª¨ë¸ ë¡œë“œ ì¤‘',
          modelName: data.model || '',
          isComplete: false
        }));
        break;
        
      case 'model_loading_complete':
        setLoadingState(prev => ({
          ...prev,
          progress: 100,
          status: 'ë¡œë”© ì™„ë£Œ!',
          title: 'ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ'
        }));
        completeLoading(3000); // 3ì´ˆ í›„ ìˆ¨ê¸°ê¸°
        break;
        
      case 'model_loading_error':
        setLoadingState(prev => ({
          ...prev,
          progress: 0,
          status: `ì˜¤ë¥˜: ${data.error}`,
          title: 'ë¡œë”© ì‹¤íŒ¨',
          isComplete: true
        }));
        completeLoading(5000); // 5ì´ˆ í›„ ìˆ¨ê¸°ê¸° (ì—ëŸ¬ëŠ” ë” ì˜¤ë˜ í‘œì‹œ)
        break;
        
      case 'model_warmup_start':
        clearAutoHideTimer();
        setLoadingState(prev => ({
          ...prev,
          isVisible: true,
          progress: 80,
          status: 'ëª¨ë¸ ì›œì—… ì¤‘...',
          title: 'ì„±ëŠ¥ ìµœì í™”',
          modelName: data.model || '',
          isComplete: false
        }));
        break;
        
      case 'model_warmup_complete':
        setLoadingState(prev => ({
          ...prev,
          progress: 100,
          status: 'ì›œì—… ì™„ë£Œ!'
        }));
        completeLoading(2000); // 2ì´ˆ í›„ ìˆ¨ê¸°ê¸°
        break;
        
      case 'cache_hit':
        // ìºì‹œ íˆíŠ¸ëŠ” ì§§ê²Œ í‘œì‹œ
        setLoadingState({
          isVisible: true,
          progress: 100,
          status: 'ìºì‹œëœ ì˜¤ë””ì˜¤ ì‚¬ìš© ì¤‘',
          title: 'ğŸš€ ì´ˆê³ ì† ì²˜ë¦¬',
          modelName: '',
          isComplete: false,
          autoHideTimer: null
        });
        completeLoading(1000); // 1ì´ˆ í›„ ìˆ¨ê¸°ê¸°
        break;
        
      case 'generation_started':
        clearAutoHideTimer();
        setLoadingState(prev => ({
          ...prev,
          isVisible: true,
          progress: 10,
          status: 'AI ìŒì„± ìƒì„± ì‹œì‘...',
          title: 'ìŒì„± í•©ì„± ì¤‘',
          modelName: data.model || '',
          isComplete: false
        }));
        break;
        
      case 'generation_metadata':
        const rtf = data.rtf || 0;
        const performance = rtf < 0.5 ? 'ğŸš€ ì´ˆê³ ì†' : rtf < 1.0 ? 'âš¡ ë¹ ë¦„' : 'âš ï¸ ë³´í†µ';
        
        setLoadingState(prev => ({
          ...prev,
          progress: 90,
          status: `ìŒì„± ìƒì„± ì™„ë£Œ (${performance})`,
          title: 'ìŒì„± ì¬ìƒ ì¤€ë¹„'
        }));
        break;
        
      case 'generation_complete':
        setLoadingState(prev => ({
          ...prev,
          progress: 100,
          status: 'ìŒì„± ìƒì„± ì™„ë£Œ!'
        }));
        completeLoading(1500); // 1.5ì´ˆ í›„ ìˆ¨ê¸°ê¸°
        break;
        
      case 'connection_established':
        const serverInfo = data.server_info || {};
        setLoadingState(prev => ({
          ...prev,
          progress: 100,
          status: 'ì„œë²„ ì—°ê²° ì™„ë£Œ!',
          title: 'ğŸ‰ ì¤€ë¹„ ì™„ë£Œ',
          modelName: serverInfo.device || ''
        }));
        completeLoading(2500); // 2.5ì´ˆ í›„ ìˆ¨ê¸°ê¸°
        break;
        
      default:
        // ê¸°íƒ€ ë°±ì—”ë“œ ì²˜ë¦¬ ìƒíƒœ
        if (data.status && (data.status.includes('ë¡œë”©') || data.status.includes('ì²˜ë¦¬'))) {
          setLoadingState(prev => ({
            ...prev,
            isVisible: true,
            status: data.status,
            isComplete: false
          }));
        }
        break;
    }
  }, [loadingState.isComplete, clearAutoHideTimer, completeLoading]);
  
  // ğŸ”¥ í”„ë¡œê·¸ë˜ìŠ¤ë°” ìˆ˜ë™ ë‹«ê¸° í•¸ë“¤ëŸ¬
  const handleCloseProgressBar = useCallback(() => {
    resetLoadingState();
  }, [resetLoadingState]);
  
  // ğŸ”¥ ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ íƒ€ì´ë¨¸ ì •ë¦¬
  useEffect(() => {
    return () => {
      clearAutoHideTimer();
    };
  }, [clearAutoHideTimer]);
  
  // ğŸ”¥ ì„¤ì • ë³€ê²½ í•¸ë“¤ëŸ¬
  const handleTTSSettingsChange = useCallback((newSettings) => {
    console.log('ğŸ­ TTS ì„¤ì • ë³€ê²½:', newSettings);
    
    const updatedSettings = {
      ...currentSettings,
      ...newSettings
    };
    
    setCurrentSettings(updatedSettings);
    
    if (isConnected) {
      // ğŸ¤ ëª©ì†Œë¦¬ ì„¤ì •ì„ tts_settingsì— í¬í•¨í•˜ì—¬ ì „ì†¡
      conversationFlow.updateSettings({
        language: "ko",
        tts_settings: {
          ...currentSettings.tts_settings,
          ...newSettings,
          // ğŸ”¥ ëª©ì†Œë¦¬ ê´€ë ¨ ë°ì´í„° ëª…ì‹œì  ì „ì†¡
          voice_id: newSettings.voice_id,
          voice_audio_base64: newSettings.voice_audio_base64,
          voice_file_path: newSettings.voice_file_path
        },
        performance_mode: "fast",
        system_prompt: "ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”. í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
      });
      
      console.log('ğŸ”¥ WebSocketìœ¼ë¡œ ì „ì†¡ëœ ëª©ì†Œë¦¬ ì„¤ì •:', {
        voice_id: newSettings.voice_id,
        voice_audio_base64: newSettings.voice_audio_base64 ? 'ë¯¸ë¯¸ë¹„ì°¸ì…ë ¥ë¨' : 'null',
        voice_file_path: newSettings.voice_file_path
      });
    }
  }, [currentSettings, isConnected, conversationFlow]);
  
  const handleVADSettingsChange = useCallback((newSettings) => {
    console.log('ğŸ¤ VAD ì„¤ì • ë³€ê²½:', newSettings);
    
    const updatedSettings = {
      ...currentSettings,
      ...newSettings
    };
    
    setCurrentSettings(updatedSettings);
    
    if (vadRecorder.isRecording && newSettings.vadConfig) {
      vadRecorder.updateVADConfig(newSettings.vadConfig);
    }
  }, [currentSettings, vadRecorder]);
  
  // ğŸ”¥ STT ê²°ê³¼ ì²˜ë¦¬
  const handleSTTResult = useCallback((transcript) => {
    console.log('ğŸ¤ STT ê²°ê³¼:', transcript);
    setCurrentTranscript(transcript);
    
    if (transcript.trim()) {
      addUserMessage(transcript);
      setCurrentStatus('thinking');
      setProcessingStep('GPT ì‘ë‹µ ìƒì„± ì¤‘...');
    } else {
      if (conversationActiveRef.current) {
        setTimeout(() => {
          setCurrentStatus('listening');
          setProcessingStep('');
          if (startListeningRef.current) {
            startListeningRef.current();
          }
        }, 1000);
      } else {
        setCurrentStatus('ready');
        setProcessingStep('');
      }
    }
  }, [addUserMessage, setCurrentTranscript]);
  
  // ğŸ”¥ GPT ì‘ë‹µ ì²˜ë¦¬
  const handleGPTResponse = useCallback((response) => {
    console.log('ğŸ¤– GPT ì‘ë‹µ:', response);
    addAssistantMessage(response);
    setCurrentStatus('talking');
    setProcessingStep('ìŒì„± ìƒì„± ì¤‘...');
  }, [addAssistantMessage]);
  
  // ğŸ”¥ TTS ì‹œì‘ ì²˜ë¦¬
  const handleTTSStart = useCallback((sampleRate, dtype) => {
    console.log('ğŸ—£ï¸ TTS ì‹œì‘');
    setSpeaking(true);
    audioPlayer.startNewAudio();
    setCurrentStatus('talking');
    setProcessingStep('ìŒì„± ì¬ìƒ ì¤‘...');
  }, [audioPlayer, setSpeaking]);
  
  // ğŸ”¥ TTS ì˜¤ë””ì˜¤ ì²˜ë¦¬
  const handleTTSAudio = useCallback(async (audioBuffer, sampleRate = 24000) => {
    try {
      await audioPlayer.playPCMChunk(audioBuffer, sampleRate);
    } catch (error) {
      console.error('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error);
      setError('ìŒì„± ì¬ìƒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  }, [audioPlayer, setError]);
  
  // ğŸ”¥ TTS ì™„ë£Œ ì²˜ë¦¬
  const handleTTSComplete = useCallback(() => {
    console.log('âœ… TTS ì™„ë£Œ');
    setSpeaking(false);
    setProcessingStep('');
    
    if (conversationActiveRef.current) {
      setTimeout(() => {
        setCurrentStatus('listening');
        if (startListeningRef.current) {
          startListeningRef.current();
        }
      }, 1500);
    } else {
      setCurrentStatus('ready');
    }
  }, [setSpeaking]);
  
  // ğŸ”¥ ì—ëŸ¬ ì²˜ë¦¬
  const handleError = useCallback((error) => {
    console.error('âŒ ëŒ€í™” ì˜¤ë¥˜:', error);
    setError(typeof error === 'string' ? error : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    setCurrentStatus('ready');
    setProcessingStep('');
    setSpeaking(false);
    setRecording(false);
    
    // ë¡œë”© í”„ë¡œê·¸ë˜ìŠ¤ë°”ë„ ìˆ¨ê¸°ê¸°
    resetLoadingState();
  }, [setError, setSpeaking, setRecording, resetLoadingState]);
  
  // ğŸ”¥ ìƒíƒœ ë³€ê²½ ì²˜ë¦¬ - ë°±ì—”ë“œ ë¡œë”© ë©”ì‹œì§€ í¬í•¨
  const handleStateChange = useCallback((state, data) => {
    console.log('ğŸ“Š ìƒíƒœ ë³€ê²½:', state, data);
    
    // ğŸ”¥ ë°±ì—”ë“œ ë¡œë”© ê´€ë ¨ ë©”ì‹œì§€ ì²˜ë¦¬
    if (data && typeof data === 'object' && data.type) {
      handleBackendLoadingMessage(data);
    }
    
    switch (state) {
      case 'connected':
        setConnected(true);
        setCurrentStatus('ready');
        break;
      case 'disconnected':
        setConnected(false);
        setCurrentStatus('disconnected');
        setConversationActive(false);
        resetLoadingState(); // ë¡œë”©ë°” ìˆ¨ê¸°ê¸°
        break;
      case 'audio_stop_previous':
        audioPlayer.startNewAudio();
        break;
    }
  }, [setConnected, audioPlayer, handleBackendLoadingMessage, resetLoadingState]);
  
  // ğŸ”¥ VAD ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤
  const handleVoiceStart = useCallback(() => {
    console.log('ğŸ¤ VAD: ìŒì„± ì‹œì‘ ê°ì§€');
    
    if (isSpeaking) {
      console.log('ğŸ”‡ TTS ì¤‘ì— ìŒì„± ê°ì§€ - TTS ì¤‘ë‹¨');
      audioPlayer.stop();
      conversationFlow.stopSpeaking();
      setSpeaking(false);
      setCurrentStatus('listening');
      setProcessingStep('ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
    } else {
      setProcessingStep('ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤...');
    }
  }, [isSpeaking, audioPlayer, conversationFlow, setSpeaking]);

  const handleVoiceEnd = useCallback(() => {
    console.log('ğŸ”‡ VAD: ìŒì„± ì¢…ë£Œ ê°ì§€');
    vadRecorder.stopRecording();
    conversationFlow.stopRecording();
    
    setRecording(false);
    setCurrentStatus('thinking');
    setProcessingStep('ìŒì„± ë¶„ì„ ì¤‘...');
  }, [vadRecorder, conversationFlow, setRecording]);

  const handleSilenceDetected = useCallback(() => {
    console.log('ğŸ¤« VAD: ê¸´ ì •ì  ê°ì§€ - ìë™ ë…¹ìŒ ì¤‘ì§€');
    if (conversationActiveRef.current && isVADEnabledRef.current) {
      setTimeout(() => {
        setCurrentStatus('listening');
        if (startListeningRef.current) {
          startListeningRef.current();
        }
      }, 1500);
    } else {
      setCurrentStatus('ready');
      setProcessingStep('');
    }
  }, []);

  const handlePCMData = useCallback((arrayBuffer) => {
    if (conversationFlow.isConnected()) {
      conversationFlow.sendVoiceData(arrayBuffer);
    }
  }, [conversationFlow]);
  
  // ğŸ”¥ ì—°ê²° ì‹œì‘
  const startConnection = useCallback(async () => {
    try {
      clearError();
      
      // ğŸ”¥ ì—°ê²° ì‹œì‘ ì‹œ ë¡œë”© í‘œì‹œ
      setLoadingState({
        isVisible: true,
        progress: 10,
        status: 'ì„œë²„ ì—°ê²° ì¤‘...',
        title: 'ì—°ê²° ì‹œì‘',
        modelName: '',
        isComplete: false,
        autoHideTimer: null
      });
      
      await audioPlayer.resumeContext();
      
      setLoadingState(prev => ({ ...prev, progress: 30, status: 'ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ' }));
      
      await conversationFlow.connectConversation(
        handleSTTResult,
        handleGPTResponse,
        handleTTSStart,
        handleTTSAudio,
        handleTTSComplete,
        handleError,
        handleStateChange
      );
      
      setLoadingState(prev => ({ ...prev, progress: 60, status: 'WebSocket ì—°ê²° ì™„ë£Œ' }));
      
      conversationFlow.updateSettings({
        language: "ko",
        ...currentSettings,
        performance_mode: "fast",
        system_prompt: "ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”. í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
      });
      
      setLoadingState(prev => ({ ...prev, progress: 90, status: 'ì„¤ì • ì ìš© ì™„ë£Œ' }));
      
      addSystemMessage('ğŸ’¬ ëŒ€í™” ì¤€ë¹„ ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.');
      
      // ë°±ì—”ë“œì—ì„œ connection_established ë©”ì‹œì§€ê°€ ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°
      
    } catch (error) {
      console.error('âŒ ì—°ê²° ì‹¤íŒ¨:', error);
      setError('ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      resetLoadingState();
    }
  }, [audioPlayer, conversationFlow, handleSTTResult, handleGPTResponse, handleTTSStart, handleTTSAudio, handleTTSComplete, handleError, handleStateChange, clearError, addSystemMessage, currentSettings, resetLoadingState]);
  
  // ğŸ”¥ ë“£ê¸° ì‹œì‘ (VAD ì§€ì›) - refë¡œ ì €ì¥
  const startListening = useCallback(async () => {
    if (!isConnected) {
      setError('ë¨¼ì € ì—°ê²°ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.');
      return;
    }
    
    try {
      setCurrentTranscript('');
      clearError();
      setProcessingStep(isVADEnabledRef.current ? 'ìŒì„±ì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤... (ìë™ ê°ì§€)' : 'ìŒì„± ì¸ì‹ ì¤‘...');
      
      if (isVADEnabledRef.current) {
        await vadRecorder.startRecording(handlePCMData, {
          onVoiceStart: handleVoiceStart,
          onVoiceEnd: handleVoiceEnd,
          onSilenceDetected: handleSilenceDetected,
          vadConfig: currentSettings.vadConfig
        });
      } else {
        await vadRecorder.startRecording(handlePCMData);
      }
      
      setRecording(true);
      setCurrentStatus('listening');
      
    } catch (error) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', error);
      setError('ë§ˆì´í¬ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.');
      setProcessingStep('');
    }
  }, [isConnected, vadRecorder, handlePCMData, handleVoiceStart, handleVoiceEnd, handleSilenceDetected, setCurrentTranscript, clearError, setRecording, setError, currentSettings.vadConfig]);
  
  useEffect(() => {
    startListeningRef.current = startListening;
  }, [startListening]);
  
  // ğŸ”¥ ë“£ê¸° ì¤‘ì§€
  const stopListening = useCallback(() => {
    vadRecorder.stopRecording();
    conversationFlow.stopRecording();
    
    setRecording(false);
    setCurrentStatus('thinking');
    setProcessingStep('ìŒì„± ë¶„ì„ ì¤‘...');
  }, [vadRecorder, conversationFlow, setRecording]);
  
  // ğŸ”¥ ëŒ€í™” ì‹œì‘ (í•œ ë²ˆ í´ë¦­ìœ¼ë¡œ ì—°ì† ëª¨ë“œ ì‹œì‘)
  const startConversation = useCallback(async () => {
    if (!isConnected) {
      await startConnection();
      return;
    }
    
    setShowAvatar(true);
    
    setConversationActive(true);
    addSystemMessage(isVADEnabled ? 'ğŸ¤– VAD ëª¨ë“œë¡œ ì—°ì† ëŒ€í™” ì‹œì‘! ìë™ìœ¼ë¡œ ìŒì„±ì„ ê°ì§€í•©ë‹ˆë‹¤.' : 'ğŸ’¬ ì—°ì† ëŒ€í™” ëª¨ë“œ ì‹œì‘! AIì™€ ììœ ë¡­ê²Œ ëŒ€í™”í•˜ì„¸ìš”.');
    
    await startListening();
  }, [isConnected, startConnection, addSystemMessage, startListening, isVADEnabled]);
  
  // ğŸ”¥ ëŒ€í™” ì¤‘ì§€
  const stopConversation = useCallback(() => {
    setConversationActive(false);
    
    vadRecorder.stopRecording();
    audioPlayer.stop();
    conversationFlow.stopSpeaking();
    
    setRecording(false);
    setSpeaking(false);
    setCurrentStatus('ready');
    setProcessingStep('');
    
    // ë¡œë”© í”„ë¡œê·¸ë˜ìŠ¤ë°”ë„ ìˆ¨ê¸°ê¸°
    resetLoadingState();
    
    addSystemMessage('ğŸ›‘ ëŒ€í™”ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.');
  }, [vadRecorder, audioPlayer, conversationFlow, setRecording, setSpeaking, addSystemMessage, resetLoadingState]);
  
  // ğŸ”¥ ì—°ê²° ì¢…ë£Œ
  const disconnect = useCallback(() => {
    stopConversation();
    conversationFlow.close();
    
    setConnected(false);
    setCurrentStatus('disconnected');
    setShowAvatar(false);
    resetLoadingState();
    addSystemMessage('ğŸ‘‹ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');
  }, [stopConversation, conversationFlow, setConnected, addSystemMessage, resetLoadingState]);
  
  // ğŸ”¥ ì „ì²´ í™”ë©´ ëª¨ë“œ ì—´ê¸°/ë‹«ê¸°
  const openFullScreen = useCallback(async () => {
    setShowFullScreen(true);
  }, []);

  const closeFullScreen = useCallback(() => {
    setShowFullScreen(false);
  }, []);

  // ğŸ”¥ ì•„ë°”íƒ€ ìƒíƒœ ê³„ì‚°
  const getAvatarAnimationClass = () => {
    if (!isConnected || !showAvatar) return 'ready';
    if (isRecording) return 'listening';
    if (isSpeaking) return 'talking';
    if (currentStatus === 'thinking') return 'thinking';
    return 'ready';
  };

  // ğŸ”¥ ìƒíƒœë³„ ë²„íŠ¼ ë° ë©”ì‹œì§€
  const getMainButton = () => {
    if (!isConnected) {
      return (
        <button 
          className="main-button connect-button"
          onClick={startConnection}
          disabled={false}
        >
          <span className="button-icon">ğŸ”Œ</span>
          <span className="button-text">ëŒ€í™” ì‹œì‘</span>
        </button>
      );
    }
    
    if (!conversationActive) {
      return (
        <>
          <button 
            className="main-button start-conversation-button"
            onClick={startConversation}
            disabled={false}
          >
            <span className="button-icon">ğŸ’¬</span>
            <span className="button-text">{isVADEnabled ? 'VAD ëŒ€í™”í•˜ê¸°' : 'ëŒ€í™”í•˜ê¸°'}</span>
            <span className="button-subtitle">{isVADEnabled ? 'ìë™ ìŒì„± ê°ì§€ ëª¨ë“œ' : 'í•œ ë²ˆ í´ë¦­ìœ¼ë¡œ ì—°ì† ëŒ€í™”'}</span>
          </button>
          
          <button 
            className="manual-button"
            onClick={startListening}
          >
            ğŸ¤ í•œ ë²ˆë§Œ ë§í•˜ê¸°
          </button>
        </>
      );
    }
    
    return (
      <button 
        className="main-button stop-conversation-button"
        onClick={stopConversation}
      >
        <span className="button-icon">ğŸ›‘</span>
        <span className="button-text">ëŒ€í™” ì¤‘ì§€</span>
      </button>
    );
  };
  
  const getStatusMessage = () => {
    const messages = {
      disconnected: 'ğŸ”´ ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤',
      ready: 'ğŸŸ¢ ëŒ€í™” ì¤€ë¹„ ì™„ë£Œ',
      listening: isVADEnabled ? 'ğŸ¤ ë§ì”€í•´ ì£¼ì„¸ìš”... (ìë™ ê°ì§€)' : 'ğŸ¤ ë§ì”€í•´ ì£¼ì„¸ìš”...',
      thinking: 'ğŸ¤” AIê°€ ìƒê°í•˜ê³  ìˆì–´ìš”...',
      talking: 'ğŸ—£ï¸ AIê°€ ë‹µë³€í•˜ê³  ìˆì–´ìš”!'
    };
    
    return messages[currentStatus] || messages.ready;
  };
  
  const getStatusColor = () => {
    const colors = {
      disconnected: '#f44336',
      ready: '#4caf50',
      listening: '#2196f3',
      thinking: '#9c27b0',
      talking: '#ff9800'
    };
    
    return colors[currentStatus] || colors.ready;
  };
  
  return (
    <>
      {/* ğŸ”¥ ë°±ì—”ë“œ ë¡œë”© í”„ë¡œê·¸ë˜ìŠ¤ë°” - ê°œì„ ëœ ì¡°ê±´ */}
      <LoadingProgressBar
        isVisible={loadingState.isVisible}
        progress={loadingState.progress}
        status={loadingState.status}
        title={loadingState.title}
        modelName={loadingState.modelName}
        onClose={loadingState.isComplete ? handleCloseProgressBar : null}
      />
      
      {/* ì „ì²´ í™”ë©´ ì•„ë°”íƒ€ ëª¨ë“œ */}
      {showFullScreen && (
        <FullScreenAvatar onClose={closeFullScreen} />
      )}
      
      <div className="simple-voice-chat">
        {/* ğŸ”¥ ìƒíƒœ í‘œì‹œ */}
        <div className="status-section">
          <div 
            className="status-indicator"
            style={{ '--status-color': getStatusColor() }}
          >
            <div className="status-pulse"></div>
            <div className="status-message">{getStatusMessage()}</div>
          </div>
          
          {processingStep && (
            <div className="processing-step">
              <div className="processing-spinner"></div>
              <span>{processingStep}</span>
            </div>
          )}
          
          {currentTranscript && (
            <div className="current-transcript">
              <span className="transcript-label">ì¸ì‹ëœ ìŒì„±:</span>
              <span className="transcript-text">"{currentTranscript}"</span>
            </div>
          )}
          
          {isVADEnabled && vadRecorder.isRecording && (
            <div className="vad-level-display">
              <div className="vad-header">
                <span className="vad-label">ìŒì„± ê°•ë„:</span>
                <span className={`vad-status ${vadRecorder.isVoiceDetected ? 'active' : 'inactive'}`}>
                  {vadRecorder.isVoiceDetected ? 'ğŸ¤ ìŒì„± ê°ì§€' : 'âšª ëŒ€ê¸° ì¤‘'}
                </span>
              </div>
              <div className="vad-level-bar">
                <div 
                  className="vad-level-fill"
                  style={{ width: `${Math.min(100, vadRecorder.voiceLevel * 100)}%` }}
                ></div>
              </div>
            </div>
          )}
        </div>

        {/* ğŸ”¥ ì•„ë°”íƒ€ í‘œì‹œ ê³µê°„ - ëŒ€í™”í•˜ê¸° ë²„íŠ¼ í´ë¦­ ì‹œ react.svg í‘œì‹œ */}
        {showAvatar && (
          <div className="avatar-space">
            <div className="avatar-placeholder">
              <img 
                src={reactSvg} 
                alt="React Avatar" 
                className={`avatar-image ${getAvatarAnimationClass()}`}
              />
              <p className="avatar-status-text">
                {getStatusMessage()}
              </p>
            </div>
          </div>
        )}
        
        {/* ğŸ”¥ ë©”ì¸ ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
        <div className="control-section">
          {getMainButton()}
          
          {isConnected && (
            <>
              <div className="settings-buttons">
                <button 
                  className={`secondary-button tts-settings-button ${showTTSControls ? 'active' : ''}`}
                  onClick={() => setShowTTSControls(!showTTSControls)}
                >
                  <span className="button-icon">ğŸ¤</span>
                  <span className="button-text">ìŒì„± ì„¤ì •</span>
                </button>
                
                <button 
                  className={`secondary-button vad-settings-button ${showVADControls ? 'active' : ''}`}
                  onClick={() => setShowVADControls(!showVADControls)}
                >
                  <span className="button-icon">ğŸ™ï¸</span>
                  <span className="button-text">VAD ì„¤ì •</span>
                </button>
                
                <button 
                  className={`secondary-button vad-toggle-button ${isVADEnabled ? 'active' : ''}`}
                  onClick={() => setIsVADEnabled(!isVADEnabled)}
                >
                  <span className="button-icon">{isVADEnabled ? 'ğŸ¤–' : 'ğŸšï¸'}</span>
                  <span className="button-text">{isVADEnabled ? 'VAD í™œì„±' : 'VAD ë¹„í™œì„±'}</span>
                </button>
              </div>

              <button 
                className="secondary-button disconnect-button"
                onClick={disconnect}
              >
                <span className="button-icon">ğŸ”Œ</span>
                <span className="button-text">ì—°ê²° í•´ì œ</span>
              </button>
            </>
          )}
        </div>

        {/* ğŸ”¥ TTS ë° ëª©ì†Œë¦¬ ì„¤ì • UI */}
        {showTTSControls && (
          <div className="settings-panel">
            <VoiceTTSControl 
              onSettingsChange={handleTTSSettingsChange}
              className="voice-tts-panel"
            />
          </div>
        )}

        {/* ğŸ”¥ VAD ì„¤ì • UI */}
        {showVADControls && (
          <div className="settings-panel">
            <VADControl 
              onSettingsChange={handleVADSettingsChange}
              currentSettings={currentSettings}
              isVisible={showVADControls}
              isRecording={vadRecorder.isRecording}
              voiceLevel={vadRecorder.voiceLevel}
              isVoiceDetected={vadRecorder.isVoiceDetected}
            />
          </div>
        )}
        
        {conversationActive && (
          <div className="conversation-mode-status">
            <div className="mode-indicator">
              <span className="mode-icon">ğŸ”„</span>
              <span className="mode-text">{isVADEnabled ? 'VAD ì—°ì† ëŒ€í™” ëª¨ë“œ í™œì„±' : 'ì—°ì† ëŒ€í™” ëª¨ë“œ í™œì„±'}</span>
            </div>
            <div className="mode-description">
              {isVADEnabled 
                ? 'AIê°€ ë§í•˜ëŠ” ì¤‘ì— ìŒì„±ì„ ê°ì§€í•˜ë©´ AI ì‘ë‹µì„ ì¤‘ë‹¨í•˜ê³  ì¦‰ì‹œ ë“£ê¸° ì‹œì‘í•©ë‹ˆë‹¤. ë§ì„ ë©ˆì¶”ë©´ ìë™ìœ¼ë¡œ ë‹¤ìŒ ëŒ€í™”ê°€ ì‹œì‘ë©ë‹ˆë‹¤.'
                : 'AI ë‹µë³€ í›„ ìë™ìœ¼ë¡œ ë‹¤ìŒ ëŒ€í™”ê°€ ì‹œì‘ë©ë‹ˆë‹¤'
              }
            </div>
          </div>
        )}

        
        {isRecording && !isVADEnabled && (
          <div className="listening-controls">
            <button 
              className="stop-listening-button"
              onClick={stopListening}
            >
              â¹ï¸ ë§í•˜ê¸° ì™„ë£Œ
            </button>
          </div>
        )}
        
        {error && (
          <div className="error-section">
            <div className="error-message">
              <span className="error-icon">âš ï¸</span>
              <span className="error-text">{error}</span>
              <button 
                className="error-close"
                onClick={clearError}
              >
                âœ•
              </button>
            </div>
          </div>
        )}
      </div>
    </>
  );
};

export default SimpleVoiceChat;