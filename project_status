
프로젝트 지침서 

프로젝트 기술‧기능 기획 v2025-05-27 (WebSocket 스트리밍)

=== 목표
- Zonos 단일 TTS 엔진으로 **실시간(≈800 ms↓)** 음성 대화 구현  
- WebSocket 양방향 스트림으로 **STT → GPT → TTS** 파이프라인 연결  
- Zonos는 Gradio 기반을 제거하고 Git clone 후 직접 백엔드화(FastAPI 내부 서비스)로 구현

=== 시스템 구성
```text
[Front (React/Vite)]  ── Mic→  /ws/stt
        │              GPT(HTTP)
        ├──────────────→ /api/gpt
        │                ←GPT 응답
        │              ↔ /ws/tts  ←(TTS chunk)
        │──Firebase(HTTP)→ 로그 저장
        ▼ AudioPlayer
[Back (FastAPI)]
   ├ /ws/stt  → Whisper-cpp
   ├ /api/gpt → DeepSeek
   └ /ws/tts  → Zonos (직접 모델 로드, Gradio 제거)
   
   
=== 기술 스택
FE: React + Vite, Zustand, Web Audio API

BE: FastAPI + Uvicorn(async)

STT: Whisper-cpp(cpu) (https://github.com/openai/whisper)

TTS: Zonos-v0.1-transformer / Zonos-v0.1-tiny(cuda) (https://github.com/Zyphra/Zonos)

DB : Firebase Firestore


=== 개발시 주의사항
- 주요사항의 경우 (DeepSeek api 혹은 firebase api key 등의 경우 .env 파일로 관리)



=== WebSocket 프로토콜
4-1. /ws/tts
단계	방향	메시지
1	클라이언트→	{ "text":"...", "model":"tiny", "format":"pcm" }
2	서버→	{ "sr":24000, "dtype":"int16" }
3	서버→	PCM 바이너리(0.2 s=4800 B)…
n	서버→	"end" 텍스트

중단: 클라이언트 "stop" → 서버 "stopped".


=== 메시지 흐름 요약  
- 클라이언트는 text + model 정보 전송  
- 서버는 샘플링 정보 전송 후, 실시간으로 오디오 chunk 전송  
- 마지막에 "end" 전송으로 합성 완료 알림  
- "stop"으로 합성 중단 요청 가능



=== /ws/stt
PCM chunk 바이너리 지속 전송

마지막 "end" 후 서버가 { "transcript":"..." } 반환



=== 디렉터리 구조 (구현 어느정도 되면 적을 예정)




=== 구현 순서
Zonos Full/Tiny 체크포인트 assets/zonos/{full,tiny}/…pth 배치

zonos_service.load() - 두 모델 CUDA 로드+LRU 1

/ws/tts 라우터 → async generator 로 PCM chunk yield

프론트 Web Audio로 실시간 재생

Firestore 스키마: sessionId, role, text, audioUrl, model, ts

길이 100자↑ 문장 split → 순차 합성·스트림


=== Zonos는 Gradio UI 기반이지만 본 프로젝트에서는 이를 제거하고 `Zonos.from_pretrained()` 직접 호출 방식으로 백엔드 FastAPI 서비스로 구현함.



=== 체크리스트
레이턴시 측정(20자 기준) < 0.8 s

Tiny 모델 VRAM 4 GB, Full 8 GB 확인

PCM vs Opus 트래픽 비교


--------현재 단계 ----------------
power shell 에서 
zonos로 이동
ps1 버전으로 하여서 실행
.\2、run_gradio.ps1
(.\2、run_gradio.bat) 이런것도 있음
웹브라우저가 열리면서 http://localhost:7860 로 접속됩니다.
인터페이스가 뜨고 텍스트 입력 + Generate 버튼이 작동하면 성공입니다.
WAV 파일 다운로드가 정상 동작해야 합니다.
현재는 cmd 에서 하면 espeak 문제가 야기하고
powershell 에서 하면 espeak 까지 정상적으로 불러와 작동 가능
cmd 에서 작동을 고쳐야지
다른 프리- 오픈 소스를 가져와도 문제가 발생하지 않을거 같음 일단
이거 고치는쪽으로 진행 해보자 => 환경 변수 고치는 것으로 고쳐짐 cmd 에서 실행 가능해짐

=> 프론트를 짜고 진행해야함 


=> 프론트는 어느정도 만들었는데 백엔드 부분을 이상하게 만들어서
전체적으로 확인요청해서 진행해야함 
whisper 다운로드 안함


===> tts 테스팅 부분은 어느정도 되었는데 
이제 음성대화할때 프로그래스바 부분이 구현이 안되어서 이 부분 해결이 필요함
그리고 속도를 올리기 위해 cpu 사용이 아닌 gpu 사용으로 변경 필요함

=> 변경은 하였으나 빌드를 못잡고 있음


torch_compile: false
지금 torch compile 가 안돌아가고 잇는데 이 부분 고치면
tts 부분 일단 문제 수정 될거 같음 

=== 현재 파일구조

C:\src\zonos\
├── Front\ChatBot\             # 프론트엔드 (React + Vite)
│   ├── src\
│   │   ├── components\
│   │   │   ├── VoiceChat.jsx      # 음성 대화 컴포넌트
│   │   │   └── TTSProgressComponent.jsx
│   │   ├── hooks\
│   │   │   ├── useAudio.js        # 🔥 오디오 문제 핵심 파일
│   │   │   ├── useConversation.js # WebSocket 통신
│   │   │   └── useWebSocket.js
│   │   └── store\                 # Zustand 상태관리
│   └── package.json
└── Zonos\                     # 백엔드 (FastAPI + Zonos)
    ├── main.py                # 🔥 메인 서버 파일
    ├── conversation_websocket.py # 🔥 대화형 WebSocket 처리
    ├── stt_service.py         # STT 서비스
    ├── gpt_service.py         # GPT 서비스
    ├── firebase_service.py    # Firebase 로깅
    ├── zonos\                 # Zonos 모델 코어
    │   ├── model.py
    │   ├── conditioning.py
    │   └── autoencoder.py
    ├── assets\                # 모델 체크포인트 저장소
    ├── .env                   # 환경변수 설정
    └── requirements-*.txt     # 의존성 관리

=== 

컨디셔닝 설정을 대폭 개선 (emotion, fmax, pitch_std 등)
바이너리 전송 → 안정적인 JSON 전송으로 되돌림
간단한 즉시 재생 방식으로 단순화




==
이제 기능들을 추가할려고해 일단은
1. 화면을  사이드 바 (껏다가 켰다가 할수 있음) (주거니 받거니 대화 하는 형식에 맞춰서 움직이는 이미지가 변하겠금 만들거야)
2. 지금 현재는 대화를 버튼 클릭으로 하고 대화하고 클릭하고 대화하는 형식인데 한번 클릭하면 대화를 인식하고 답변하고 그다음에 대화를 하고 답변하고 하는식으로 할 예정이야 (대화 중지 버튼도 만들고)
3. 좀 더 프로그래스바 같은 액션감을 추가할 계획이야  (tts에 테스트에는 있는데 나머지 모델을 불러오거나 모듈을 호출하거나 로딩중에는 프로그래스 바가 없는 상태야 )







-== 메모장
TTS 속도 최적화 완료!
모든 최적화 작업이 완료되었습니다! 다음과 같은 개선사항들이 적용되었습니다:
✅ 완료된 작업들
📄 새 파일 생성:
tts_speed_optimization.py - 캐싱, 병렬처리, 웜업 시스템
🔧 main.py 수정:
울트라 최적화된 오디오 생성 함수 추가
캐시 시스템 통합
병렬 처리 지원
모델 웜업 시스템
성능 모니터링 강화
⚙️ .env 설정 추가:
캐시 시스템 설정
병렬 처리 설정
성능 최적화 옵션
📁 디렉토리 생성:
cache/tts/ 캐시 저장소
🆕 API 엔드포인트 추가:
/api/cache/stats - 캐시 통계
/api/cache/clear - 캐시 삭제
/api/performance/stats - 전체 성능 통계
🚀 예상 성능 향상
상황기존 속도최적화 후개선율첫 번째 요청1.5초0.8초47% ⬆️
동일 텍스트 재요청1.5초0.05초97% ⬆️
긴 텍스트 (150자+)4.2초2.3초45% ⬆️