import asyncio
import json
import logging
import time
from typing import Dict, Optional, Any
import numpy as np
from concurrent.futures import ThreadPoolExecutor

import torch
from fastapi import WebSocket, WebSocketDisconnect

# Zonos ëª¨ë¸ import ì¶”ê°€
from zonos.model import Zonos

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ğŸ”¥ ê¸€ë¡œë²Œ ìŠ¤ë ˆë“œ í’€ - ë³‘ë ¬ ì²˜ë¦¬ìš©
executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix="zonos-")

# ì´ í•¨ìˆ˜ë“¤ì€ main.pyì—ì„œ ì£¼ì…ë  ì˜ˆì •
model_cache = None
make_cond_dict = None
device = None
log_user_message = None
log_assistant_message = None
log_system_message = None
get_gpt_service = None
get_stt_service = None

def set_dependencies(deps):
    """main.pyì—ì„œ ì˜ì¡´ì„±ë“¤ì„ ì£¼ì…"""
    global model_cache, make_cond_dict, device, log_user_message, log_assistant_message, log_system_message, get_gpt_service, get_stt_service
    model_cache = deps['model_cache']
    make_cond_dict = deps['make_cond_dict']
    device = deps['device']
    log_user_message = deps['log_user_message']
    log_assistant_message = deps['log_assistant_message']
    log_system_message = deps['log_system_message']
    get_gpt_service = deps['get_gpt_service']
    get_stt_service = deps['get_stt_service']

# ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜ë“¤
def log_performance_metrics(operation: str, start_time: float, **kwargs):
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…"""
    duration = time.time() - start_time
    logger.info(f"â±ï¸ {operation}: {duration:.3f}ì´ˆ")
    
    # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        logger.info(f"ğŸ§  GPU ë©”ëª¨ë¦¬: {allocated:.2f}GB")

# ğŸ¯ ì§€ì› ëª¨ë¸ í™•ì¸ í•¨ìˆ˜
def get_best_model_for_task(requested_model: str = None, task_type: str = "general") -> str:
    """ì‘ì—…ì— ìµœì í™”ëœ ëª¨ë¸ ì„ íƒ"""
    supported_models = [
        "Zyphra/Zonos-v0.1-transformer"  # ğŸ”¥ ìœ ì¼í•œ ì‘ë™í•˜ëŠ” ëª¨ë¸
    ]
    
    if requested_model and requested_model in supported_models:
        return requested_model
    
    # ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì²˜ë¦¬
    if requested_model:
        if "hybrid" in requested_model.lower() or "tiny" in requested_model.lower():
            logger.warning(f"âš ï¸ {requested_model}ì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. transformer ëª¨ë¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            return "Zyphra/Zonos-v0.1-transformer"
    
    # ğŸ”¥ ëª¨ë“  ì‘ì—…ì— ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš© (tiny ëª¨ë¸ ì—†ìŒ)
    return "Zyphra/Zonos-v0.1-transformer"

# ëŒ€í™”í˜• WebSocket ê´€ë¦¬ì
class ConversationManager:
    def __init__(self):
        self.active_conversations: Dict[str, WebSocket] = {}
        self.conversation_states: Dict[str, Dict[str, Any]] = {}
        self.audio_buffers: Dict[str, bytearray] = {}
        self.performance_stats: Dict[str, Dict] = {}  # ì„±ëŠ¥ í†µê³„
    
    def is_connected(self, client_id: str) -> bool:
        """í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìƒíƒœ í™•ì¸"""
        return client_id in self.active_conversations
    
    async def safe_send_json(self, client_id: str, data: dict) -> bool:
        """ì•ˆì „í•œ JSON ë©”ì‹œì§€ ì „ì†¡"""
        if not self.is_connected(client_id):
            logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id}ê°€ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŒ")
            return False
        
        try:
            websocket = self.active_conversations[client_id]
            await websocket.send_json(data)
            return True
        except Exception as e:
            logger.error(f"âŒ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨ (í´ë¼ì´ì–¸íŠ¸ {client_id}): {e}")
            # ì—°ê²°ì´ ëŠì–´ì§„ ê²½ìš° ì •ë¦¬
            if client_id in self.active_conversations:
                del self.active_conversations[client_id]
            return False
    
    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_conversations[client_id] = websocket
        self.conversation_states[client_id] = {
            "session_active": True,
            "waiting_for_response": False,
            "current_message": "",
            "language": "ko",
            "preferred_model": "Zyphra/Zonos-v0.1-transformer",  # ê¸°ë³¸ê°’ì„ ì§€ì›ë˜ëŠ” ëª¨ë¸ë¡œ
            "performance_mode": "auto"  # auto, fast, quality
        }
        self.audio_buffers[client_id] = bytearray()
        self.performance_stats[client_id] = {
            "total_requests": 0,
            "avg_stt_time": 0,
            "avg_gpt_time": 0,
            "avg_tts_time": 0,
            "session_start": time.time()
        }
        
        logger.info(f"ğŸ”— Client {client_id} connected to conversation WebSocket")
        logger.info(f"ğŸ¯ ê¸°ë³¸ ëª¨ë¸: {self.conversation_states[client_id]['preferred_model']}")
        
        # ğŸ”¥ í”„ë¡ íŠ¸ì—”ë“œì— ì—°ê²° ì™„ë£Œ ì‹ í˜¸ ì „ì†¡
        await self.safe_send_json(client_id, {
            "type": "connection_established",
            "event": "connection_established",
            "message": "ì„œë²„ ì—°ê²°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
            "server_info": {
                "device": str(device),
                "model": self.conversation_states[client_id]['preferred_model'],
                "gpu_available": torch.cuda.is_available(),
                "status": "ready"
            }
        })
        
        # ì—°ê²° ì‹œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë¡œê·¸
        try:
            await log_system_message(
                client_id, 
                "ëŒ€í™” ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
                metadata={
                    "event": "session_start",
                    "device": str(device),
                    "default_model": self.conversation_states[client_id]['preferred_model']
                }
            )
        except Exception as e:
            logger.warning(f"âš ï¸ Firebase ë¡œê¹… ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
    
    def disconnect(self, client_id: str):
        if client_id in self.active_conversations:
            del self.active_conversations[client_id]
        if client_id in self.conversation_states:
            del self.conversation_states[client_id]
        if client_id in self.audio_buffers:
            del self.audio_buffers[client_id]
        if client_id in self.performance_stats:
            # ì„¸ì…˜ ì¢…ë£Œ ì‹œ ì„±ëŠ¥ í†µê³„ ë¡œê¹…
            stats = self.performance_stats[client_id]
            session_duration = time.time() - stats["session_start"]
            logger.info(f"ğŸ“Š ì„¸ì…˜ {client_id} í†µê³„: ìš”ì²­ {stats['total_requests']}íšŒ, ì§€ì†ì‹œê°„ {session_duration:.1f}ì´ˆ")
            del self.performance_stats[client_id]
        
        logger.info(f"ğŸ”Œ Client {client_id} disconnected from conversation WebSocket")

# ğŸ”¥ ì´ˆê³ ì† ëŒ€í™” íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤
class FastConversationPipeline:
    """ì´ˆê³ ì† ëŒ€í™” íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.model_cache = {}
        self.preprocessing_cache = {}
        
    async def parallel_stt_gpt_pipeline(self, websocket: WebSocket, client_id: str, audio_data: bytes):
        """STTì™€ GPT ì¤€ë¹„ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬"""
        start_time = time.time()
        
        # ğŸ”¥ ë³‘ë ¬ ì‘ì—… ì •ì˜
        async def fast_stt_task():
            stt_service = get_stt_service()
            return await stt_service.transcribe_audio_async(audio_data, sample_rate=16000)
        
        async def prepare_gpt_task():
            # GPT ì„œë¹„ìŠ¤ ì›Œë°ì—…
            gpt = get_gpt_service()
            return gpt
            
        async def prepare_tts_task():
            # TTS ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ
            tiny_model = "Zyphra/Zonos-v0.1-tiny"
            return model_cache.load_model_if_needed(tiny_model)
        
        # ğŸ”¥ 3ê°€ì§€ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰
        try:
            stt_result, gpt_service, tts_model = await asyncio.gather(
                fast_stt_task(),
                prepare_gpt_task(),
                prepare_tts_task(),
                return_exceptions=True
            )
            
            if isinstance(stt_result, Exception):
                raise stt_result
                
            parallel_time = time.time() - start_time
            logger.info(f"âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {parallel_time:.2f}ì´ˆ")
            
            return stt_result, gpt_service, tts_model, parallel_time
            
        except Exception as e:
            logger.error(f"âŒ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise e

    async def ultra_fast_response(self, websocket: WebSocket, client_id: str, transcript: str):
        """ì´ˆê³ ì† GPT + TTS ì‘ë‹µ ìƒì„±"""
        
        # ğŸ”¥ ë§¤ìš° ì§§ì€ ì‘ë‹µì„ ìœ„í•œ íŠ¹ë³„ í”„ë¡¬í”„íŠ¸  
        ultra_short_prompt = f"3ë‹¨ì–´ ì´ë‚´ë¡œ ê°„ë‹¨íˆ: {transcript}"
        
        gpt_start = time.time()
        gpt = get_gpt_service()
        
        # ğŸ”¥ ê·¹ë„ë¡œ ì œí•œëœ GPT ì‘ë‹µ
        response = await gpt.chat_completion(
            session_id=client_id,
            user_message=ultra_short_prompt,
            max_tokens=15,  # ê·¹ë„ë¡œ ì œí•œ
            temperature=0.3,  # ë” ê²°ì •ì ì¸ ì‘ë‹µ
            top_p=0.8
        )
        
        gpt_time = time.time() - gpt_start
        logger.info(f"âš¡ ì´ˆê³ ì† GPT: {gpt_time:.2f}ì´ˆ, ì‘ë‹µ: '{response}'")
        
        # ğŸ”¥ TTS ì¦‰ì‹œ ì‹œì‘ (GPT ì™„ë£Œì™€ ë™ì‹œì—)
        await self.instant_tts_generation(websocket, client_id, response)
        
        return response, gpt_time

    async def instant_tts_generation(self, websocket: WebSocket, client_id: str, text: str):
        """ì¦‰ì‹œ TTS ìƒì„± - ìµœì†Œ ì§€ì—°"""
        
        if not text.strip():
            return
            
        tts_start = time.time()
        
        # ğŸ”¥ ê°€ì¥ ë¹ ë¥¸ ì„¤ì •ìœ¼ë¡œ TTS
        tiny_model = model_cache.load_model_if_needed("Zyphra/Zonos-v0.1-tiny")
        
        # ğŸ¤ ëª©ì†Œë¦¬ ì²˜ë¦¬ (ì´ˆê³ ì† ëª¨ë“œì—ì„œë„ ì ìš©)
        state = conversation_manager.conversation_states.get(client_id, {})
        tts_settings = state.get("tts_settings", {})
        
        from voice_manager import VoiceManager
        voice_manager = VoiceManager(device)
        speaker_embedding = await voice_manager.process_voice_request(tts_settings, tiny_model)
        
        # ğŸ”¥ ì´ˆê³ ì† ì»¨ë””ì…”ë‹ (ëª©ì†Œë¦¬ ì ìš©)
        fast_cond_dict = make_cond_dict(
            text=text,
            language="ko",
            speaker=speaker_embedding,  # ğŸ”¥ ëª©ì†Œë¦¬ ì„ë² ë”© ì ìš©!
            emotion=[0.8, 0.1, 0.1],  # ê°„ì†Œí™”ëœ ê°ì •
            fmax=16000.0,  # ë‚®ì€ ì£¼íŒŒìˆ˜ (ë” ë¹ ë¦„)
            pitch_std=15.0,
            speaking_rate=25.0,  # ë¹ ë¥¸ ë§í•˜ê¸°
            device=device,
            unconditional_keys=set()  # ë¹„ì¡°ê±´ë¶€ í‚¤ ì œê±°
        )
        
        conditioning = tiny_model.prepare_conditioning(fast_cond_dict)
        
        # ğŸ”¥ ê·¹ë„ë¡œ ìµœì í™”ëœ ìƒì„± íŒŒë¼ë¯¸í„°
        text_len = len(text.strip())
        max_tokens = min(500, text_len * 40)  # ë§¤ìš° ì ì€ í† í°
        
        codes = tiny_model.generate(
            prefix_conditioning=conditioning,
            max_new_tokens=max_tokens,
            cfg_scale=1.0,  # ë‚®ì€ CFGë¡œ ë¹ ë¥¸ ìƒì„±
            batch_size=1,
            sampling_params=dict(min_p=0.15, temperature=0.9),
            progress_bar=False,
            disable_torch_compile=True
        )
        
        # ì˜¤ë””ì˜¤ ë””ì½”ë”©
        wav_out = tiny_model.autoencoder.decode(codes).cpu().detach()
        audio_data = wav_out.squeeze().numpy()
        
        # ì¦‰ì‹œ ì „ì†¡
        await self.instant_audio_stream(websocket, client_id, audio_data, tiny_model.autoencoder.sampling_rate)
        
        tts_time = time.time() - tts_start
        logger.info(f"âš¡ ì´ˆê³ ì† TTS: {tts_time:.2f}ì´ˆ")
        
        return tts_time

    async def instant_audio_stream(self, websocket: WebSocket, client_id: str, audio_data, sample_rate: int):
        """ì¦‰ì‹œ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° - ìµœì†Œ ì§€ì—°"""
        
        # ğŸ”¥ ë” ì‘ì€ ì²­í¬ë¡œ ë” ë¹ ë¥¸ ìŠ¤íŠ¸ë¦¬ë°
        chunk_size = int(sample_rate * 0.02)  # 20ms ì²­í¬
        
        # ì •ê·œí™”
        max_val = abs(audio_data).max()
        if max_val > 0:
            audio_data = audio_data / max_val * 0.9
        
        # 16ë¹„íŠ¸ ë³€í™˜
        audio_int16 = (audio_data * 32767).astype('int16')
        
        # ğŸ”¥ ë©”íƒ€ë°ì´í„° ë¨¼ì € ì „ì†¡
        await conversation_manager.safe_send_json(client_id, {
            "event": "instant_audio_start",
            "sr": sample_rate,
            "total_size": len(audio_int16),
            "chunk_size": chunk_size
        })
        
        # ğŸ”¥ ì´ˆê³ ì† ìŠ¤íŠ¸ë¦¬ë° (ì§€ì—° ìµœì†Œí™”)
        for i in range(0, len(audio_int16), chunk_size):
            chunk = audio_int16[i:i + chunk_size]
            chunk_bytes = chunk.tobytes()
            
            try:
                await websocket.send_bytes(chunk_bytes)
                await asyncio.sleep(0.003)  # 3ms ì§€ì—°ë§Œ
            except Exception as e:
                logger.warning(f"âš ï¸ ì¦‰ì‹œ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨: {e}")
                break
        
        # ì™„ë£Œ ì‹ í˜¸
        await conversation_manager.safe_send_json(client_id, {
            "event": "instant_audio_complete"
        })

conversation_manager = ConversationManager()

async def websocket_conversation(websocket: WebSocket, client_id: str):
    """í†µí•© ëŒ€í™” WebSocket - STT, GPT, TTSë¥¼ ëª¨ë‘ ì²˜ë¦¬"""
    await conversation_manager.connect(websocket, client_id)
    
    try:
        while True:
            data = await websocket.receive()
            
            if "text" in data:
                message = data["text"]
                
                if message == "stop_recording":
                    await handle_stt_completion(websocket, client_id)
                    
                elif message == "stop_speaking":
                    await conversation_manager.safe_send_json(client_id, {"event": "tts_stopped"})
                    
                elif message.startswith("{"):
                    try:
                        config = json.loads(message)
                        await handle_configuration(websocket, client_id, config)
                    except json.JSONDecodeError:
                        await conversation_manager.safe_send_json(client_id, {"error": "Invalid JSON configuration"})
                        
            elif "bytes" in data:
                await handle_stt_audio_chunk(websocket, client_id, data["bytes"])
                
    except WebSocketDisconnect:
        conversation_manager.disconnect(client_id)
        try:
            await log_system_message(
                client_id, 
                "ëŒ€í™” ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                metadata={"event": "session_end"}
            )
        except Exception as e:
            logger.warning(f"âš ï¸ Firebase ë¡œê¹… ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
    except Exception as e:
        logger.error(f"âŒ Conversation WebSocket error: {e}")
        conversation_manager.disconnect(client_id)

async def handle_configuration(websocket: WebSocket, client_id: str, config: Dict[str, Any]):
    """ì„¤ì • ë³€ê²½ ì²˜ë¦¬"""
    # ì—°ê²° ìƒíƒœ í™•ì¸
    if not conversation_manager.is_connected(client_id):
        logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§ - ì„¤ì • ë³€ê²½ ë¬´ì‹œ")
        return
        
    state = conversation_manager.conversation_states.get(client_id, {})
    
    # ì–¸ì–´ ì„¤ì •
    if "language" in config:
        state["language"] = config["language"]
    
    # TTS ì„¤ì •
    if "tts_settings" in config:
        state["tts_settings"] = config["tts_settings"]
        
        # ëª¨ë¸ ì„¤ì •ë„ í•¨ê»˜ ê²€ì¦
        if "model" in config["tts_settings"]:
            requested_model = config["tts_settings"]["model"]
            validated_model = get_best_model_for_task(requested_model)
            
            if requested_model != validated_model:
                logger.warning(f"âš ï¸ ëª¨ë¸ {requested_model} â†’ {validated_model} ë³€ê²½")
                config["tts_settings"]["model"] = validated_model
                state["tts_settings"]["model"] = validated_model
            
            state["preferred_model"] = validated_model
    
    # ì„±ëŠ¥ ëª¨ë“œ ì„¤ì •
    if "performance_mode" in config:
        performance_mode = config["performance_mode"]
        state["performance_mode"] = performance_mode
        
        # ğŸ”¥ ì„±ëŠ¥ ëª¨ë“œì— ê´€ê³„ì—†ì´ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš© (tiny ëª¨ë¸ ì—†ìŒ)
        state["preferred_model"] = "Zyphra/Zonos-v0.1-transformer"
        
        logger.info(f"ğŸ¯ ì„±ëŠ¥ ëª¨ë“œ: {performance_mode}, ëª¨ë¸: {state['preferred_model']}")
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    if "system_prompt" in config:
        state["system_prompt"] = config["system_prompt"]
    
    await conversation_manager.safe_send_json(client_id, {
        "event": "config_updated",
        "settings": state,
        "device_info": {
            "device": str(device),
            "gpu_available": torch.cuda.is_available()
        }
    })

async def handle_stt_audio_chunk(websocket: WebSocket, client_id: str, audio_chunk: bytes):
    """STT ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬"""
    if client_id not in conversation_manager.audio_buffers:
        conversation_manager.audio_buffers[client_id] = bytearray()
    
    conversation_manager.audio_buffers[client_id].extend(audio_chunk)
    logger.debug(f"ğŸ¤ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ : {len(audio_chunk)} bytes, ì´: {len(conversation_manager.audio_buffers[client_id])} bytes")

async def handle_stt_completion(websocket: WebSocket, client_id: str):
    """STT ì™„ë£Œ ì²˜ë¦¬ ë° GPT í˜¸ì¶œ"""
    start_time = time.time()
    
    try:
        # ì—°ê²° ìƒíƒœ í™•ì¸
        if not conversation_manager.is_connected(client_id):
            logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§ - STT ì²˜ë¦¬ ì¤‘ë‹¨")
            return
            
        audio_buffer = conversation_manager.audio_buffers.get(client_id)
        
        if not audio_buffer or len(audio_buffer) == 0:
            await conversation_manager.safe_send_json(client_id, {"event": "stt_empty"})
            return
        
        stt_service = get_stt_service()
        audio_data = bytes(audio_buffer)
        
        logger.info(f"ğŸ¤ STT ì²˜ë¦¬ ì‹œì‘: {len(audio_data)} bytes")
        
        # STT ì²˜ë¦¬
        if stt_service.available:
            transcript = await stt_service.transcribe_audio_async(
                audio_data, sample_rate=16000
            )
            logger.info(f"âœ… STT ì²˜ë¦¬ ì™„ë£Œ: {transcript}")
        else:
            transcript = stt_service._dummy_stt_for_testing()
            logger.warning("âš ï¸ Using dummy STT - Whisper not available")
        
        # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
        stt_time = time.time() - start_time
        if client_id in conversation_manager.performance_stats:
            stats = conversation_manager.performance_stats[client_id]
            stats["avg_stt_time"] = (stats["avg_stt_time"] * stats["total_requests"] + stt_time) / (stats["total_requests"] + 1)
        
        conversation_manager.audio_buffers[client_id] = bytearray()
        
        if not transcript.strip():
            await conversation_manager.safe_send_json(client_id, {"event": "stt_empty"})
            return
        
        # ì—°ê²° ìƒíƒœ ì¬í™•ì¸
        if not conversation_manager.is_connected(client_id):
            logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§ - STT ì™„ë£Œ í›„ ì²˜ë¦¬ ì¤‘ë‹¨")
            return
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ë¡œê·¸ (ì›ë³¸ í…ìŠ¤íŠ¸ë¡œ ë¡œê¹…, í”„ë¦¬í”½ìŠ¤ ì œì™¸)
        try:
            await log_user_message(
                client_id, 
                transcript,  # ğŸ”¥ ì›ë³¸ ë‚´ìš©ë§Œ ë¡œê¹… (í”„ë¦¬í”½ìŠ¤ ì œì™¸)
                metadata={
                    "source": "voice_input", 
                    "audio_length": len(audio_data),
                    "stt_time": stt_time,
                    "device": str(device),
                    "enhanced_with_prefix": True  # ğŸ”¥ í”„ë¦¬í”½ìŠ¤ ì¶”ê°€ í”Œë˜ê·¸
                }
            )
        except Exception as e:
            logger.warning(f"âš ï¸ Firebase ë¡œê¹… ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
        
        # STT ê²°ê³¼ ì „ì†¡
        if not await conversation_manager.safe_send_json(client_id, {
            "event": "stt_completed",
            "transcript": transcript,
            "processing_time": stt_time
        }):
            logger.warning(f"âš ï¸ STT ê²°ê³¼ ì „ì†¡ ì‹¤íŒ¨ - í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§")
            return
        
        # GPT ì‘ë‹µ ìƒì„±
        await generate_gpt_response(websocket, client_id, transcript)
        
    except Exception as e:
        logger.error(f"âŒ STT completion error: {e}")
        await conversation_manager.safe_send_json(client_id, {"error": f"STT processing failed: {str(e)}"})

async def generate_gpt_response(websocket: WebSocket, client_id: str, user_message: str):
    """GPT ì‘ë‹µ ìƒì„±"""
    start_time = time.time()
    
    try:
        # ì—°ê²° ìƒíƒœ í™•ì¸
        if not conversation_manager.is_connected(client_id):
            logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§ - GPT ì²˜ë¦¬ ì¤‘ë‹¨")
            return
            
        gpt = get_gpt_service()
        state = conversation_manager.conversation_states.get(client_id, {})
        system_prompt = state.get("system_prompt")
        
        logger.info(f"ğŸ¤– GPT ì‘ë‹µ ìƒì„± ì‹œì‘")
        
        # GPT ì²˜ë¦¬ ì‹œì‘ ì•Œë¦¼
        await conversation_manager.safe_send_json(client_id, {
            "event": "gpt_processing",
            "message": "AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
        })
        
        # ğŸ”¥ ì§§ì€ ë‹µë³€ì„ ìœ„í•œ í”„ë¦¬í”½ìŠ¤ ì¶”ê°€
        enhanced_message = f"í•œì¤„ ë°˜ ì •ë„ë¡œ ê°„ë‹¨í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”: {user_message}"
        logger.info(f"ğŸ¯ í”„ë¦¬í”½ìŠ¤ ì¶”ê°€ëœ ë©”ì‹œì§€: '{enhanced_message}'")
        
        response = await gpt.chat_completion(
            session_id=client_id,
            user_message=enhanced_message,
            system_prompt=system_prompt,
            max_tokens=100  # ğŸ”¥ ë”ìš± ì§§ì€ ë‹µë³€ì„ ìœ„í•´ í† í° ìˆ˜ ì¶”ê°€ ì œí•œ
        )
        
        # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
        gpt_time = time.time() - start_time
        if client_id in conversation_manager.performance_stats:
            stats = conversation_manager.performance_stats[client_id]
            stats["avg_gpt_time"] = (stats["avg_gpt_time"] * stats["total_requests"] + gpt_time) / (stats["total_requests"] + 1)
        
        logger.info(f"âœ… GPT ì§§ì€ ì‘ë‹µ ìƒì„± ì™„ë£Œ: {gpt_time:.2f}ì´ˆ, ì‘ë‹µ ê¸¸ì´: {len(response)}ì")
        
        # ì—°ê²° ìƒíƒœ ì¬í™•ì¸
        if not conversation_manager.is_connected(client_id):
            logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§ - GPT ì™„ë£Œ í›„ ì²˜ë¦¬ ì¤‘ë‹¨")
            return
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ë¡œê·¸
        try:
            await log_assistant_message(
                client_id,
                response,
                metadata={
                    "source": "gpt_response", 
                    "model": "deepseek-chat",
                    "gpt_time": gpt_time,
                    "device": str(device),
                    "response_length": len(response),  # ğŸ”¥ ì‘ë‹µ ê¸¸ì´ ì¶”ê°€
                    "short_response_mode": True  # ğŸ”¥ ì§§ì€ ë‹µë³€ ëª¨ë“œ í”Œë˜ê·¸
                }
            )
        except Exception as e:
            logger.warning(f"âš ï¸ Firebase ë¡œê¹… ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
        
        # GPT ì§§ì€ ì‘ë‹µ ì „ì†¡
        if not await conversation_manager.safe_send_json(client_id, {
            "event": "gpt_response",
            "response": response,
            "processing_time": gpt_time,
            "response_length": len(response),  # ğŸ”¥ ì‘ë‹µ ê¸¸ì´ ì •ë³´ ì¶”ê°€
            "mode": "short_response"  # ğŸ”¥ ì§§ì€ ë‹µë³€ ëª¨ë“œ í‘œì‹œ
        }):
            logger.warning(f"âš ï¸ GPT ì§§ì€ ì‘ë‹µ ì „ì†¡ ì‹¤íŒ¨ - í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§")
            return
        
        # ìë™ìœ¼ë¡œ TTS ìƒì„± (ì§§ì€ ì‘ë‹µ ë²„ì „)
        await generate_tts_response(websocket, client_id, response)
        
    except Exception as e:
        logger.error(f"âŒ GPT response error: {e}")
        await conversation_manager.safe_send_json(client_id, {"error": f"GPT processing failed: {str(e)}"})

async def generate_tts_response(websocket: WebSocket, client_id: str, text: str):
    """TTS ì‘ë‹µ ìƒì„± - ë‹¨ìˆœí™” ë° ì•ˆì •ì„± í–¥ìƒ"""
    start_time = time.time()
    
    try:
        if not text.strip():
            logger.warning(f"âš ï¸ Empty text for TTS generation for client {client_id}")
            return
        
        logger.info(f"ğŸµ TTS ìƒì„± ì‹œì‘ (client {client_id}): '{text[:50]}...'")
        
        # ëŒ€í™” ìƒíƒœì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        state = conversation_manager.conversation_states.get(client_id, {})
        tts_settings = state.get("tts_settings", {})
        language = state.get("language", "ko")
        performance_mode = state.get("performance_mode", "auto")
        
        # ëª¨ë¸ ì„ íƒ
        requested_model = tts_settings.get("model") or state.get("preferred_model")
        # ğŸ”¥ ëª¨ë“  ëª¨ë“œì—ì„œ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©
        model_choice = get_best_model_for_task(requested_model, "general")
        
        logger.info(f"ğŸ¯ TTS ëª¨ë¸ ì„ íƒ: {model_choice} (ëª¨ë“œ: {performance_mode})")
        
        # ì—°ê²° ìƒíƒœ í™•ì¸
        if not conversation_manager.is_connected(client_id):
            logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§ - TTS ì²˜ë¦¬ ì¤‘ë‹¨")
            return
        
        # TTS ì‹œì‘ ì•Œë¦¼
        await conversation_manager.safe_send_json(client_id, {
            "event": "tts_progress",
            "progress": 10,
            "message": f"TTS ëª¨ë¸ ë¡œë”©... ({model_choice})",
            "model": model_choice
        })
        
        # ëª¨ë¸ ë¡œë“œ
        model = model_cache.load_model_if_needed(model_choice)
        logger.info(f"âœ… Model loaded successfully: {model_choice}")
        
        # ğŸ¤ ëª©ì†Œë¦¬ ê´€ë¦¬ìë¥¼ í†µí•œ ìŠ¤í”¼ì»¤ ì„ë² ë”© ì²˜ë¦¬
        from voice_manager import VoiceManager
        voice_manager = VoiceManager(device)
        
        # ëª©ì†Œë¦¬ ì„¤ì • ì²˜ë¦¬
        speaker_embedding = await voice_manager.process_voice_request(tts_settings, model)
        
        logger.info(f"ğŸ¤ ëª©ì†Œë¦¬ ì²˜ë¦¬ ê²°ê³¼: {'ì»¤ìŠ¤í…€ ëª©ì†Œë¦¬' if speaker_embedding is not None else 'ê¸°ë³¸ ëª©ì†Œë¦¬'}")
        
        # ì»¨ë””ì…”ë‹ ì„¤ì • - ìŒì§ˆ ê°œì„  ë° ëª©ì†Œë¦¬ ì ìš©
        improved_emotion = tts_settings.get("emotion", [0.7, 0.05, 0.05, 0.05, 0.1, 0.05, 0.3, 0.15])
        cond_dict = make_cond_dict(
            text=text,
            language=language,
            speaker=speaker_embedding,  # ğŸ”¥ ëª©ì†Œë¦¬ ì„ë² ë”© ì ìš©!
            emotion=improved_emotion,
            fmax=tts_settings.get("fmax", 24000.0),
            pitch_std=tts_settings.get("pitch_std", 30.0),
            speaking_rate=tts_settings.get("speaking_rate", 20.0),
            vqscore_8=tts_settings.get("vqscore_8", [0.9] * 8),
            dnsmos_ovrl=tts_settings.get("dnsmos_ovrl", 4.5),
            device=device,
            unconditional_keys={"vqscore_8", "dnsmos_ovrl"}
        )
        
        conditioning = model.prepare_conditioning(cond_dict)
        logger.info(f"ğŸ›ï¸ Conditioning prepared for language: {language}")
        
        # ì˜¤ë””ì˜¤ ìƒì„± ì‹œì‘ ì•Œë¦¼
        await conversation_manager.safe_send_json(client_id, {
            "event": "tts_progress",
            "progress": 50,
            "message": "ìŒì„± ìƒì„± ì¤‘..."
        })
        
        # ğŸ”¥ ì˜¤ë””ì˜¤ ìƒì„± - íŒŒë¼ë¯¸í„° ìµœì í™”
        generation_start = time.time()
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ í† í° ìˆ˜ ê³„ì‚° (í•œê¸€ìë‹¹ ì•½ 80-120 í† í°)
        text_length = len(text.strip())
        min_tokens_per_char = 80
        max_tokens_per_char = 120
        estimated_tokens = text_length * min_tokens_per_char
        max_new_tokens = min(86 * 30, max(estimated_tokens, text_length * max_tokens_per_char))
        
        logger.info(f"ğŸ¯ í† í° ê³„ì‚°: í…ìŠ¤íŠ¸ ê¸¸ì´={text_length}, ì˜ˆìƒ í† í°={estimated_tokens}, max_new_tokens={max_new_tokens}")
        
        cfg_scale = tts_settings.get("cfg_scale", 1.5)  # CFG ìŠ¤ì¼€ì¼ ë” ë‚®ì¶¤
        
        codes = model.generate(
            prefix_conditioning=conditioning,
            audio_prefix_codes=None,
            max_new_tokens=max_new_tokens,
            cfg_scale=cfg_scale,
            batch_size=1,
            sampling_params=dict(
                min_p=0.05,
                temperature=0.85,
                top_k=40
            ),
            progress_bar=False,
            disable_torch_compile=True,
        )
        
        generation_time = time.time() - generation_start
        logger.info(f"âœ… Audio codes generated in {generation_time:.2f}s: {codes.shape}")
        
        # ì˜¤ë””ì˜¤ ë””ì½”ë”©
        decode_start = time.time()
        wav_out = model.autoencoder.decode(codes).cpu().detach()
        if wav_out.dim() == 2 and wav_out.size(0) > 1:
            wav_out = wav_out[0:1, :]
        
        audio_data = wav_out.squeeze().numpy()
        decode_time = time.time() - decode_start
        
        total_time = generation_time + decode_time
        audio_duration = len(audio_data) / model.autoencoder.sampling_rate
        rtf = total_time / audio_duration if audio_duration > 0 else 0
        
        logger.info(f"ğŸ¶ ì˜¤ë””ì˜¤ ë””ì½”ë”© ì™„ë£Œ: {audio_data.shape}, ì§€ì†ì‹œê°„: {audio_duration:.2f}s, RTF: {rtf:.2f}")
        
        # ğŸ”¥ ì˜¤ë””ì˜¤ í’ˆì§ˆ ê°œì„  ì²˜ë¦¬ ë° ë””ë²„ê¹… ê°•í™”
        max_val = np.abs(audio_data).max()
        logger.info(f"ğŸ” ì›ë³¸ ì˜¤ë””ì˜¤ ë°ì´í„° ë¶„ì„: max={max_val:.6f}, ê¸¸ì´={len(audio_data)}, ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°={audio_data[:10]}")
        
        if max_val > 0:
            # ë” ë¶€ë“œëŸ¬ìš´ ì •ê·œí™”
            audio_data = audio_data / max_val
            audio_data = np.tanh(audio_data * 0.9) * 0.8  # soft limiting
            audio_data = audio_data - np.mean(audio_data)  # DC ì œê±°
            logger.info(f"ğŸ›ï¸ ì •ê·œí™” í›„ ì˜¤ë””ì˜¤: max={np.abs(audio_data).max():.6f}, mean={np.mean(audio_data):.6f}")
        else:
            logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¬´ìŒì…ë‹ˆë‹¤! max_val={max_val}")
            # ë¬´ìŒ ë°ì´í„°ì¸ ê²½ìš° ì‘ì€ í…ŒìŠ¤íŠ¸ í†¤ì„ ìƒì„±
            logger.info("ğŸµ í…ŒìŠ¤íŠ¸ í†¤ ìƒì„± ì¤‘...")
            sr_out = model.autoencoder.sampling_rate
            duration = 0.5  # 0.5ì´ˆ
            t = np.linspace(0, duration, int(sr_out * duration))
            audio_data = 0.1 * np.sin(2 * np.pi * 440 * t)  # 440Hz í…ŒìŠ¤íŠ¸ í†¤
            logger.info(f"ğŸµ í…ŒìŠ¤íŠ¸ í†¤ ìƒì„±ë¨: max={np.abs(audio_data).max():.6f}, ê¸¸ì´={len(audio_data)}")
        
        # PCM 16-bit ë³€í™˜
        audio_int16 = np.clip(audio_data * 32767, -32768, 32767).astype('int16')
        logger.info(f"ğŸ“Š PCM 16-bit ë³€í™˜: max={np.abs(audio_int16).max()}, ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°={audio_int16[:10]}")
        
        # ğŸ”¥ JSON ë°©ì‹ìœ¼ë¡œ ê°„ë‹¨íˆ ì „ì†¡ - ë””ë²„ê¹… ê°•í™”
        import base64
        audio_bytes = audio_int16.tobytes()
        logger.info(f"ğŸ“Š ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°°ì—´ ìƒì„±: ê¸¸ì´={len(audio_bytes)}, ì²˜ìŒ 20ë°”ì´íŠ¸={audio_bytes[:20]}")
        
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        logger.info(f"ğŸ“¦ Base64 ì¸ì½”ë”© ì™„ë£Œ: ê¸¸ì´={len(audio_base64)}, ì²˜ìŒ 50ë¬¸ì={audio_base64[:50]}...")
        
        # TTS ì‹œì‘ ì‹ í˜¸ ë¨¼ì € ì „ì†¡
        sr_out = model.autoencoder.sampling_rate
        if not await conversation_manager.safe_send_json(client_id, {
            "event": "tts_started",
            "sr": int(sr_out),
            "dtype": "int16",
            "text": text,
            "model": model_choice
        }):
            return
        
        logger.info(f"ğŸ“¡ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ ì‹œì‘: {len(audio_bytes)} bytes")
        
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡
        audio_message = {
            "event": "audio_data_complete",
            "audio_data": audio_base64,
            "sample_rate": int(sr_out),
            "duration": audio_duration,
            "rtf": rtf,
            "generation_time": total_time,
            "model": model_choice,
            "format": "pcm_int16_base64"
        }
        
        # ì—°ê²° ìƒíƒœ ì¬í™•ì¸ í›„ ì „ì†¡
        if not conversation_manager.is_connected(client_id):
            logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§ - ì˜¤ë””ì˜¤ ì „ì†¡ ì¤‘ë‹¨")
            return
        
        if not await conversation_manager.safe_send_json(client_id, audio_message):
            logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ ì‹¤íŒ¨")
            return
        
        # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
        tts_time = time.time() - start_time
        if client_id in conversation_manager.performance_stats:
            stats = conversation_manager.performance_stats[client_id]
            stats["avg_tts_time"] = (stats["avg_tts_time"] * stats["total_requests"] + tts_time) / (stats["total_requests"] + 1)
            stats["total_requests"] += 1
        
        # ì™„ë£Œ ì‹ í˜¸
        await conversation_manager.safe_send_json(client_id, {
            "event": "tts_completed",
            "processing_time": tts_time,
            "model": model_choice,
            "device": str(device),
            "performance": "ğŸš€ ì‹¤ì‹œê°„" if tts_time < 1.0 else "âš ï¸ ëŠë¦¼"
        })
        
        logger.info(f"âœ… TTS generation completed for client {client_id} in {tts_time:.2f}s")
        
        # Firebaseì— TTS ë¡œê·¸
        try:
            await log_assistant_message(
                client_id,
                text,
                metadata={
                    "type": "tts_audio",
                    "model": model_choice,
                    "language": language,
                    "tts_params": tts_settings,
                    "tts_time": tts_time,
                    "device": str(device),
                    "performance_mode": performance_mode,
                    "rtf": rtf,
                    "audio_duration": audio_duration
                }
            )
        except Exception as e:
            logger.warning(f"âš ï¸ Firebase ë¡œê¹… ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
        
    except Exception as e:
        logger.error(f"âŒ TTS generation error for client {client_id}: {e}")
        await conversation_manager.safe_send_json(client_id, {"error": f"TTS generation failed: {str(e)}"})


async def stream_conversation_audio(
    client_id: str,
    websocket: WebSocket,
    model: Zonos,
    conditioning: torch.Tensor,
    tts_settings: Dict[str, Any],
    model_name: str = "unknown",
    original_text: str = ""  # ì›ë³¸ í…ìŠ¤íŠ¸ ì¶”ê°€
):
    """ëŒ€í™”ìš© ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° - ì¤‘ë³µ ë°©ì§€ ë° íš¨ìœ¨ì„± ê°œì„ """
    import numpy as np
    generation_start = time.time()
    
    try:
        logger.info(f"ğŸµ ì˜¤ë””ì˜¤ ìƒì„± ì‹œì‘ (ëª¨ë¸: {model_name})")
        
        # ğŸ”¥ ì´ì „ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ ì‹ í˜¸ ë¨¼ì € ì „ì†¡
        await conversation_manager.safe_send_json(client_id, {
            "event": "audio_stop_previous",
            "message": "ì´ì „ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ ì¤‘..."
        })
        
        # ì˜¤ë””ì˜¤ ìƒì„± íŒŒë¼ë¯¸í„° ìµœì í™” - ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´ ì‚¬ìš©
        if original_text.strip():
            text_length = len(original_text.strip())
        else:
            # í´ë°±: conditioning ê¸°ë°˜ ì¶”ì •
            text_length = max(4, len(str(conditioning)) // 100)
            
        min_tokens_per_char = 85
        max_tokens_per_char = 130
        estimated_tokens = text_length * min_tokens_per_char
        max_new_tokens = min(86 * 30, max(estimated_tokens, text_length * max_tokens_per_char))
        
        logger.info(f"ğŸ¯ ìŠ¤íŠ¸ë¦¬ë° í† í° ê³„ì‚°: í…ìŠ¤íŠ¸ ê¸¸ì´={text_length}, max_new_tokens={max_new_tokens}, ì›ë³¸ í…ìŠ¤íŠ¸='{original_text[:20]}...'")
        
        cfg_scale = tts_settings.get("cfg_scale", 1.8)  # ğŸ”¥ CFG ìŠ¤ì¼€ì¼ ë‚®ì¶¤ (í’ˆì§ˆ vs ì†ë„)
        
        batch_size = 1
        
        codes = model.generate(
            prefix_conditioning=conditioning,
            audio_prefix_codes=None,
            max_new_tokens=max_new_tokens,
            cfg_scale=cfg_scale,
            batch_size=batch_size,
            sampling_params=dict(
                min_p=0.08,  # ğŸ”¥ min_p ì¡°ì •ìœ¼ë¡œ í’ˆì§ˆ ê°œì„ 
                temperature=0.7  # ğŸ”¥ ì˜¨ë„ ì¶”ê°€ë¡œ ë” ìì—°ìŠ¤ëŸ½ê²Œ
            ),
            progress_bar=False,
            disable_torch_compile=True,  # ì»´íŒŒì¼ ë¹„í™œì„±í™” (ì•ˆì •ì„±)
        )
        
        generation_time = time.time() - generation_start
        logger.info(f"âœ… Audio codes generated in {generation_time:.2f}s: {codes.shape}")
        
        # ì˜¤ë””ì˜¤ ë””ì½”ë”©
        decode_start = time.time()
        wav_out = model.autoencoder.decode(codes).cpu().detach()
        if wav_out.dim() == 2 and wav_out.size(0) > 1:
            wav_out = wav_out[0:1, :]
        
        audio_data = wav_out.squeeze().numpy()
        decode_time = time.time() - decode_start
        
        total_time = generation_time + decode_time
        audio_duration = len(audio_data) / model.autoencoder.sampling_rate
        rtf = total_time / audio_duration if audio_duration > 0 else 0
        
        logger.info(f"ğŸ¶ ì˜¤ë””ì˜¤ ë””ì½”ë”© ì™„ë£Œ: {audio_data.shape}, ì§€ì†ì‹œê°„: {audio_duration:.2f}s, RTF: {rtf:.2f}")
        
        # ğŸ”¥ ì˜¤ë””ì˜¤ í’ˆì§ˆ ê°œì„  - ì •ê·œí™” ë° ë…¸ì´ì¦ˆ ì œê±°
        # ë³¼ë¥¨ ì •ê·œí™”
        max_val = np.abs(audio_data).max()
        if max_val > 0:
            audio_data = audio_data / max_val * 0.8  # 80%ë¡œ ì œí•œí•˜ì—¬ í´ë¦¬í•‘ ë°©ì§€
        
        # ğŸ”¥ ì²­í¬ ë‹¨ìœ„ë¡œ ì „ì†¡ - ë” í° ì²­í¬ë¡œ ì•ˆì •ì„± í–¥ìƒ
        sr = model.autoencoder.sampling_rate
        chunk_duration = 0.3  # ğŸ”¥ 0.3ì´ˆë¡œ ì²­í¬ í¬ê¸° ì¦ê°€ (ì•ˆì •ì„± í–¥ìƒ)
        chunk_size = int(sr * chunk_duration)
        total_chunks = (len(audio_data) + chunk_size - 1) // chunk_size
        
        logger.info(f"ğŸ“¡ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: {total_chunks} ì²­í¬ (ì²­í¬ í¬ê¸°: {chunk_size})")
        
        # ğŸ”¥ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ë©”ì‹œì§€ì— ê³ ìœ  ID ì¶”ê°€
        stream_id = f"stream_{client_id}_{int(time.time() * 1000)}"
        await conversation_manager.safe_send_json(client_id, {
            "event": "audio_stream_start",
            "stream_id": stream_id,
            "total_chunks": total_chunks,
            "sample_rate": int(sr),
            "model": model_name,
            "rtf": rtf
        })
        
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i + chunk_size]
            chunk_index = i // chunk_size
            
            # PCM 16-bit ë³€í™˜
            chunk_int16 = (chunk * 32767).astype('int16')
            
            # ğŸ”¥ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¡œ ì „ì†¡ (JSON ë¹„íš¨ìœ¨ì„± í•´ê²°)
            # ë©”íƒ€ë°ì´í„° ë¨¼ì € ì „ì†¡
            metadata = {
                "event": "audio_chunk_meta",
                "stream_id": stream_id,
                "chunk_index": chunk_index,
                "total_chunks": total_chunks,
                "sample_rate": int(sr),
                "chunk_size": len(chunk_int16),
                "model": model_name,
                "rtf": rtf,
                "is_final_chunk": chunk_index == total_chunks - 1
            }
            
            # ì—°ê²° ìƒíƒœ í™•ì¸ í›„ ì „ì†¡
            if not conversation_manager.is_connected(client_id):
                logger.warning(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠì–´ì§ - ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨")
                break
            
            # ë©”íƒ€ë°ì´í„° ì „ì†¡
            if not await conversation_manager.safe_send_json(client_id, metadata):
                logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì „ì†¡ ì‹¤íŒ¨ - ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨")
                break
                
            # ğŸ”¥ ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡ (íš¨ìœ¨ì ) - ë””ë²„ê¹… ê°•í™”
            try:
                chunk_bytes = chunk_int16.tobytes()
                logger.debug(f"ğŸ“¤ ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¤: {len(chunk_bytes)} bytes, ì²­í¬ {chunk_index + 1}/{total_chunks}")
                await websocket.send_bytes(chunk_bytes)
                logger.debug(f"âœ… ë°”ì´ë„ˆë¦¬ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡ ì„±ê³µ: {chunk_index + 1}/{total_chunks}")
            except Exception as e:
                logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ ë°”ì´ë„ˆë¦¬ ì „ì†¡ ì‹¤íŒ¨: {e}")
                break
            
            logger.debug(f"ğŸ“¤ ì²­í¬ ì „ì†¡ {chunk_index + 1}/{total_chunks}")
            
            # ğŸ”¥ ì ì‘í˜• ì§€ì—° ê°œì„  - RTF ê¸°ë°˜
            if rtf < 0.3:
                delay = 0.02  # ë§¤ìš° ë¹ ë¦„
            elif rtf < 0.7:
                delay = 0.05  # ë¹ ë¦„
            else:
                delay = 0.1   # ì¼ë°˜
            
            await asyncio.sleep(delay)
        
        # ğŸ”¥ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ë©”ì‹œì§€
        await conversation_manager.safe_send_json(client_id, {
            "event": "audio_stream_complete",
            "stream_id": stream_id,
            "total_chunks_sent": total_chunks,
            "total_duration": audio_duration,
            "generation_time": total_time,
            "rtf": rtf
        })
        
        logger.info(f"âœ… ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: {total_chunks} ì²­í¬, RTF: {rtf:.2f}")
            
    except Exception as e:
        logger.error(f"âŒ Conversation audio streaming error: {e}")
        await conversation_manager.safe_send_json(client_id, {
            "error": f"Audio streaming failed: {str(e)}",
            "event": "audio_stream_error"
        })

def add_conversation_routes(app):
    """FastAPI ì•±ì— ëŒ€í™”í˜• WebSocket ë¼ìš°í„° ì¶”ê°€"""
    
    @app.websocket("/ws/conversation/{client_id}")
    async def websocket_conversation_route(websocket: WebSocket, client_id: str):
        await websocket_conversation(websocket, client_id)


# ğŸ”¥ ì´ˆê³ ì† ëŒ€í™” íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤
fast_pipeline = FastConversationPipeline()

# ğŸ”¥ ê¸°ì¡´ í•¨ìˆ˜ë¥¼ ëŒ€ì²´í•˜ëŠ” ì´ˆê³ ì† ë²„ì „
async def ultra_fast_stt_completion(websocket: WebSocket, client_id: str):
    """ì´ˆê³ ì† STT ì™„ë£Œ ì²˜ë¦¬"""
    
    total_start = time.time()
    
    try:
        audio_buffer = conversation_manager.audio_buffers.get(client_id)
        if not audio_buffer or len(audio_buffer) == 0:
            return
        
        audio_data = bytes(audio_buffer)
        conversation_manager.audio_buffers[client_id] = bytearray()
        
        # ğŸ”¥ ë³‘ë ¬ ì²˜ë¦¬ë¡œ STT, GPT, TTS ì¤€ë¹„
        transcript, gpt_service, tts_model, parallel_time = await fast_pipeline.parallel_stt_gpt_pipeline(
            websocket, client_id, audio_data
        )
        
        if not transcript.strip():
            return
        
        logger.info(f"âš¡ STT ê²°ê³¼: '{transcript}' ({parallel_time:.2f}ì´ˆ)")
        
        # STT ê²°ê³¼ ì¦‰ì‹œ ì „ì†¡
        await conversation_manager.safe_send_json(client_id, {
            "event": "ultra_fast_stt",
            "transcript": transcript,
            "processing_time": parallel_time
        })
        
        # ğŸ”¥ ì´ˆê³ ì† GPT + TTS (ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼ í™œìš©)
        response, gpt_time = await fast_pipeline.ultra_fast_response(websocket, client_id, transcript)
        
        total_time = time.time() - total_start
        logger.info(f"ğŸš€ ì „ì²´ ëŒ€í™” íŒŒì´í”„ë¼ì¸: {total_time:.2f}ì´ˆ (ëª©í‘œ: <0.5ì´ˆ)")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì „ì†¡
        await conversation_manager.safe_send_json(client_id, {
            "event": "ultra_fast_complete",
            "total_time": total_time,
            "stt_time": parallel_time,
            "gpt_time": gpt_time,
            "performance": "ğŸš€ ì´ˆê³ ì†" if total_time < 0.5 else "âš¡ ê³ ì†"
        })
        
    except Exception as e:
        logger.error(f"âŒ ì´ˆê³ ì† ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        await conversation_manager.safe_send_json(client_id, {"error": str(e)})
